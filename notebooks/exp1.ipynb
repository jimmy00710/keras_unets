{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout,BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, Concatenate, MaxPooling2D\n",
    "from tensorflow.keras.layers import UpSampling2D, Dropout, BatchNormalization\n",
    "from keras.utils import conv_utils\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.layers.core import Activation, SpatialDropout2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import Xception as Xception\n",
    "from tensorflow.keras.applications import DenseNet169 as Densenet\n",
    "from tensorflow.keras.applications import ResNet50 as Resnet\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import ZeroPadding2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(\n",
    "    x,\n",
    "    filters,\n",
    "    kernel,\n",
    "    strides=(1,1),\n",
    "    padding='same',\n",
    "    activation=None,\n",
    "    trainable=True,\n",
    "):\n",
    "    '''\n",
    "    X - Input features,\n",
    "    filters - Output dimension\n",
    "    kernel - (2,2) Convolution or (3,3) Convolution\n",
    "    strides - Number of steps taken for consecutive convolution,\n",
    "    padding = 'same' --> Same across the left,right,top and bottom. or valid --> No padding,\n",
    "    activation = Activation Layer to be applied.\n",
    "    '''\n",
    "    #Input - (224,224,3)\n",
    "    #Conv2D \n",
    "    #- strides --> It divides the input. So it reduce the size of the input. Since we are hoping.\n",
    "    #- kernel --> \n",
    "\n",
    "    x = Conv2D(filters,\n",
    "            kernel,\n",
    "            strides,\n",
    "            padding)(x)  \n",
    "    x = BatchNormalization(trainable=trainable)(x)  #BatchNorm does not change the dimension of the input. \n",
    "\n",
    "    if activation != None:\n",
    "        if activation == 'relu':\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "        elif activation == 'leakyrelu':\n",
    "            x = tf.keras.layers.Activation('leakyrelu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(\n",
    "    block_input,\n",
    "    num_filters,):\n",
    "  \n",
    "    block_input1 = BatchNormalization()(block_input) #Just adding a precautionary layer, of getting specialized features.\n",
    "    '''\n",
    "    We can pass the normalized features to a RELU layer, or we don't it depend on us.\n",
    "    Let's not pass it. \n",
    "    '''\n",
    "    x = tf.keras.layers.Activation('relu')(block_input)\n",
    "    print(x.shape)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = conv_block(x,\n",
    "                 filters=num_filters,\n",
    "                 kernel=(3,3),\n",
    "                 strides=(1,1),\n",
    "                 activation='relu')\n",
    "\n",
    "    x = conv_block(x,\n",
    "                 num_filters,\n",
    "                 (3,3),\n",
    "                 strides=(1,1),\n",
    "                 activation=None)\n",
    "    print(x.shape)\n",
    "\n",
    "    #Assuming the size of the blockinput1 and x is same we will add them.\n",
    "    #For sanity purpose we will pass the x with a batchnorm.\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    return tf.keras.layers.Add()([x,block_input1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UXception(input_shape=(None, None, 3),dropout_rate=0.5):\n",
    "\n",
    "    backbone = Xception(input_shape=input_shape,weights='imagenet',include_top=False)\n",
    "    input = backbone.input\n",
    "    start_neurons = 16\n",
    "\n",
    "    conv4 = backbone.layers[121].output # 32,32,1024\n",
    "    conv4 = LeakyReLU(alpha=0.1)(conv4) # 32,32,1024\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4) # 16,16,1024\n",
    "    pool4 = Dropout(dropout_rate)(pool4) # 16,16,1024\n",
    "    \n",
    "     # Middle\n",
    "    convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4) # 16,16,512\n",
    "    convm = residual_block(convm,start_neurons * 32) # 16,16,512\n",
    "    convm = residual_block(convm,start_neurons * 32) # 16,16,512\n",
    "    convm = LeakyReLU(alpha=0.1)(convm) # 16,16,512\n",
    "    \n",
    "    deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm) # 32,32,256\n",
    "    uconv4 = concatenate([deconv4, conv4]) # 32,32,1280\n",
    "    uconv4 = Dropout(dropout_rate)(uconv4) # 32,32,1280\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4) # 32,32,256\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 16) # 32,32,256\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 16) # 32,32,256\n",
    "    uconv4 = LeakyReLU(alpha=0.1)(uconv4) # 32,32,256\n",
    "    \n",
    "    deconv3 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4) #64,64,128\n",
    "    conv3 = backbone.layers[31].output # 64,64,728\n",
    "    uconv3 = concatenate([deconv3, conv3])   #64,64,956 \n",
    "    uconv3 = Dropout(dropout_rate)(uconv3) # 64,64,956\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3) # 64,64,128\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 8) # 64,64,128\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 8) # 64,64,128\n",
    "    uconv3 = LeakyReLU(alpha=0.1)(uconv3) # 64,64,128\n",
    "\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3) # 128,128,64\n",
    "    conv2 = backbone.layers[21].output # 127,127,256\n",
    "    conv2 = ZeroPadding2D(((1,0),(1,0)))(conv2) # 128,128,256\n",
    "    uconv2 = concatenate([deconv2, conv2]) # 128,128,320\n",
    "        \n",
    "    uconv2 = Dropout(0.1)(uconv2) # 128,128,320\n",
    "    uconv2 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2) # 128,128,64\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 4) # 128,128,64\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 4) # 128,128,64\n",
    "    uconv2 = LeakyReLU(alpha=0.1)(uconv2) # 128,128,64\n",
    "    \n",
    "    deconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2) # 256,256,32\n",
    "    conv1 = backbone.layers[11].output # 253,253,128\n",
    "    conv1 = ZeroPadding2D(((3,0),(3,0)))(conv1) # 256,256,128\n",
    "    uconv1 = concatenate([deconv1, conv1]) # 256,256,160\n",
    "    \n",
    "    uconv1 = Dropout(0.1)(uconv1) # 256,256,160\n",
    "    uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1) # 256,256,32\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 2) # 256,256,32\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 2) # 256,256,32\n",
    "    uconv1 = LeakyReLU(alpha=0.1)(uconv1) # 256,256,32\n",
    "    \n",
    "    uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   # 512,512,16\n",
    "    uconv0 = Dropout(dropout_rate)(uconv0) #512,512,16\n",
    "    uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0) # 512,512,16\n",
    "    uconv0 = residual_block(uconv0,start_neurons * 1) # 512,512,16\n",
    "    uconv0 = residual_block(uconv0,start_neurons * 1) # 512,512,16\n",
    "    uconv0 = LeakyReLU(alpha=0.1)(uconv0) # 512,512,16\n",
    "    \n",
    "    uconv0 = Dropout(dropout_rate/2)(uconv0) # 512,512,16\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv0)    # 512,512,1\n",
    "    \n",
    "    model = Model(input, output_layer)\n",
    "    #model.name = 'u-xception'\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(input_block,\n",
    "          start_neurons,\n",
    "          multiplying_factor,\n",
    "          kernel=(3,3),\n",
    "          strides=(1,1),\n",
    "          padding='same'):\n",
    "    \n",
    "    output_filters = start_neurons * multiplying_factor\n",
    "    \n",
    "    output_block = Conv2D(output_filters,kernel,activation=None,strides=strides,padding=padding)(input_block)\n",
    "    output_block = residual_block(output_block,output_filters)\n",
    "    output_block = residual_block(output_block,output_filters)\n",
    "    output_block = LeakyReLU(alpha=0.1)(output_block)\n",
    "    return output_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upconv_block(backbone,\n",
    "                input_block,\n",
    "                layer_number,\n",
    "                start_neurons,\n",
    "                multiplying_factor,\n",
    "                kernel=(3,3),\n",
    "                stride=(2,2),\n",
    "                padding='same',\n",
    "                padding_kernel=1,\n",
    "                padding_flag=True,\n",
    "                dropout_rate=0.1):\n",
    "    \n",
    "    print(f'The input block shape is {input_block.shape}')\n",
    "    \n",
    "    output_filters = start_neurons * multiplying_factor\n",
    "    upconv = Conv2DTranspose(output_filters,kernel,strides=stride,padding='same')(input_block)\n",
    "    layer_output = backbone.layers[layer_number].output\n",
    "    print(f'The layer output is {layer_output.shape}')\n",
    "    print(f'The upconv output is shape {upconv.shape}')\n",
    "    print(f'The padding flag is set to {padding_flag} and padding is {padding_kernel}')\n",
    "    \n",
    "    if padding_flag == True:\n",
    "        print('Inside zero padding')\n",
    "        layer_output = ZeroPadding2D(((int(padding_kernel),0),(int(padding_kernel),0)))(layer_output)\n",
    "        print(f'Updated layer_output shape is {layer_output}')\n",
    "    \n",
    "    output = concatenate([upconv,layer_output])\n",
    "    dropout = Dropout(dropout_rate)(output)\n",
    "    \n",
    "    return dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unets(backbone_encoder,input_shape=(None, None, 3),dropout_rate=0.5,start_neurons=16):\n",
    "    \n",
    "    if backbone_encoder='Xception':\n",
    "        \n",
    "    backbone = Xception(input_shape=input_shape,weights='imagenet',include_top=False)\n",
    "    input = backbone.input\n",
    "    \n",
    "    conv4 = backbone.layers[121].output # 32,32,1024 #16,16,1600\n",
    "    conv4 = LeakyReLU(alpha=0.1)(conv4) # 32,32,1024 #16,16,1600\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4) # 16,16,1024  #8,8,1600\n",
    "    pool4 = Dropout(dropout_rate)(pool4) # 16,16,1024 #8,8,1600\n",
    "    \n",
    "    #Middle \n",
    "    convm = convolutional_block(pool4,start_neurons=16,multiplying_factor=32) # m64, 8,8,1024\n",
    "    \n",
    "#     deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm) # 32,32,256\n",
    "#     uconv4 = concatenate([deconv4, conv4]) # 32,32,1280\n",
    "#     uconv4 = Dropout(dropout_rate)(uconv4) # 32,32,1280\n",
    "    \n",
    "    \n",
    "    #Decoder\n",
    "    uconv4 = upconv_block(backbone,convm,layer_number=121,start_neurons=16,multiplying_factor=16,dropout_rate=0.5,padding_flag=False)\n",
    "    uconv4 = convolutional_block(uconv4,start_neurons=16,multiplying_factor=16)\n",
    "    \n",
    "    uconv3 = upconv_block(backbone,uconv4,layer_number=31,start_neurons=16,multiplying_factor=8,padding_flag=False,dropout_rate=0.5)\n",
    "    uconv3 = convolutional_block(uconv3,start_neurons=16,multiplying_factor=8)\n",
    "    \n",
    "    uconv2 = upconv_block(backbone,uconv3,layer_number=21,start_neurons=16,multiplying_factor=4,padding_kernel=1,padding_flag=True)\n",
    "    uconv2 = convolutional_block(uconv2,start_neurons=16,multiplying_factor=4)\n",
    "    \n",
    "    uconv1 = upconv_block(backbone,uconv2,layer_number=11,start_neurons=16,multiplying_factor=2,padding_kernel=3,padding_flag=True)\n",
    "    uconv1 = convolutional_block(uconv1,start_neurons=16,multiplying_factor=2)\n",
    "    \n",
    "    uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   # 512,512,16\n",
    "    uconv0 = Dropout(dropout_rate)(uconv0) #512,512,16\n",
    "    uconv0 = convolutional_block(uconv0,start_neurons=16,multiplying_factor=1,strides=(1,1))\n",
    "    \n",
    "    uconv0 = Dropout(dropout_rate/2)(uconv0) # 512,512,16\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv0)    # 512,512,1\n",
    "    \n",
    "    model = Model(input, output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uxception = Xception(input_shape=(512,512,3),weights='imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 255, 255, 32) 864         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 255, 255, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 255, 255, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 253, 253, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 253, 253, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 253, 253, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 253, 253, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 253, 253, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 253, 253, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 253, 253, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 253, 253, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 127, 127, 128 8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 127, 127, 128 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 127, 127, 128 512         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, 127, 127, 128 0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 127, 127, 128 0           add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 127, 127, 256 33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 127, 127, 256 1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 127, 127, 256 0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 127, 127, 256 67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 127, 127, 256 1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 64, 64, 256)  32768       add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 64, 64, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 64, 64, 256)  1024        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 64, 64, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 64, 64, 256)  0           add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 64, 64, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 64, 64, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 64, 64, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 64, 64, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 64, 64, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 32, 32, 728)  186368      add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 32, 32, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 32, 32, 728)  2912        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 32, 32, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 32, 32, 728)  0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 32, 32, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 32, 32, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 32, 32, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 32, 32, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 32, 32, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 32, 32, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 32, 32, 728)  0           add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 32, 32, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 32, 32, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 32, 32, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 32, 32, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 32, 32, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 32, 32, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 32, 32, 728)  0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 32, 32, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 32, 32, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 32, 32, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 32, 32, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 32, 32, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 32, 32, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 32, 32, 728)  0           add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 32, 32, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 32, 32, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 32, 32, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 32, 32, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 32, 32, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 32, 32, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 32, 32, 728)  0           add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 32, 32, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 32, 32, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 32, 32, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 32, 32, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 32, 32, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_97 (Add)                    (None, 32, 32, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 32, 32, 728)  0           add_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 32, 32, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 32, 32, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 32, 32, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 32, 32, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 32, 32, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 32, 32, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 32, 32, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 32, 32, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_98 (Add)                    (None, 32, 32, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 32, 32, 728)  0           add_98[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 32, 32, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 32, 32, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 32, 32, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 32, 32, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 32, 32, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 32, 32, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 32, 32, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 32, 32, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_99 (Add)                    (None, 32, 32, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_98[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 32, 32, 728)  0           add_99[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 32, 32, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 32, 32, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 32, 32, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 32, 32, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 32, 32, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 32, 32, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 32, 32, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 32, 32, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_100 (Add)                   (None, 32, 32, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_99[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 32, 32, 728)  0           add_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 32, 32, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 32, 32, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 32, 32, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 32, 32, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 32, 32, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 32, 32, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 1024) 0           leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 16, 16, 1024) 0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 16, 16, 512)  4719104     dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 512)  0           conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 16, 16, 512)  2048        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 16, 16, 512)  2359808     batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 16, 16, 512)  2048        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 512)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 16, 16, 512)  2359808     activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 16, 16, 512)  2048        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 16, 16, 512)  2048        batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 16, 16, 512)  2048        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_102 (Add)                   (None, 16, 16, 512)  0           batch_normalization_122[0][0]    \n",
      "                                                                 batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 512)  0           add_102[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 16, 16, 512)  2048        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 16, 16, 512)  2359808     batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 16, 16, 512)  2048        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 512)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 16, 16, 512)  2359808     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 16, 16, 512)  2048        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 16, 16, 512)  2048        batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 16, 16, 512)  2048        add_102[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_103 (Add)                   (None, 16, 16, 512)  0           batch_normalization_127[0][0]    \n",
      "                                                                 batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 16, 16, 512)  0           add_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 32, 32, 256)  1179904     leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 1280) 0           conv2d_transpose_8[0][0]         \n",
      "                                                                 leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 32, 32, 1280) 0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 256)  2949376     dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 32, 32, 256)  0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 32, 32, 256)  1024        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 32, 32, 256)  590080      batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 32, 32, 256)  1024        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 32, 32, 256)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 32, 32, 256)  590080      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 32, 32, 256)  1024        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 32, 32, 256)  1024        batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 32, 32, 256)  1024        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_104 (Add)                   (None, 32, 32, 256)  0           batch_normalization_132[0][0]    \n",
      "                                                                 batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 32, 32, 256)  0           add_104[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 32, 32, 256)  1024        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 32, 32, 256)  590080      batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 32, 32, 256)  1024        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 32, 32, 256)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 32, 32, 256)  590080      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 32, 32, 256)  1024        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 32, 32, 256)  1024        batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 32, 32, 256)  1024        add_104[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_105 (Add)                   (None, 32, 32, 256)  0           batch_normalization_137[0][0]    \n",
      "                                                                 batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 32, 32, 256)  0           add_105[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 64, 64, 128)  295040      leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 856)  0           conv2d_transpose_9[0][0]         \n",
      "                                                                 block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 64, 64, 856)  0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 64, 64, 128)  986240      dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 64, 64, 128)  0           conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 64, 64, 128)  512         activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 64, 64, 128)  147584      batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 64, 64, 128)  512         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 64, 64, 128)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 64, 64, 128)  147584      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 64, 64, 128)  512         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 64, 64, 128)  512         batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 64, 64, 128)  512         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_106 (Add)                   (None, 64, 64, 128)  0           batch_normalization_142[0][0]    \n",
      "                                                                 batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 64, 64, 128)  0           add_106[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 64, 64, 128)  512         activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 64, 64, 128)  147584      batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 64, 64, 128)  512         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 64, 64, 128)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 64, 64, 128)  147584      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 64, 64, 128)  512         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 64, 64, 128)  512         batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 64, 64, 128)  512         add_106[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_107 (Add)                   (None, 64, 64, 128)  0           batch_normalization_147[0][0]    \n",
      "                                                                 batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 64, 64, 128)  0           add_107[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 128, 128, 64) 73792       leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 128, 128, 256 0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 128, 128, 320 0           conv2d_transpose_10[0][0]        \n",
      "                                                                 zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 128, 128, 320 0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 128, 128, 64) 184384      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 128, 128, 64) 0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 128, 128, 64) 256         activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 128, 128, 64) 36928       batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 128, 128, 64) 256         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 128, 128, 64) 0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 128, 128, 64) 36928       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 128, 128, 64) 256         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 128, 128, 64) 256         batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 128, 128, 64) 256         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_108 (Add)                   (None, 128, 128, 64) 0           batch_normalization_152[0][0]    \n",
      "                                                                 batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128, 128, 64) 0           add_108[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 128, 128, 64) 256         activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 128, 128, 64) 36928       batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 128, 128, 64) 256         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 128, 128, 64) 0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 128, 128, 64) 36928       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 128, 128, 64) 256         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 128, 128, 64) 256         batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 128, 128, 64) 256         add_108[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_109 (Add)                   (None, 128, 128, 64) 0           batch_normalization_157[0][0]    \n",
      "                                                                 batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 128, 128, 64) 0           add_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 256, 256, 32) 18464       leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 256, 256, 128 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 256, 256, 160 0           conv2d_transpose_11[0][0]        \n",
      "                                                                 zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 256, 256, 160 0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 256, 256, 32) 46112       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 256, 256, 32) 0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 256, 256, 32) 128         activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 256, 256, 32) 9248        batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 256, 256, 32) 128         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 256, 256, 32) 0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 256, 256, 32) 9248        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 256, 256, 32) 128         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 256, 256, 32) 128         batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 256, 256, 32) 128         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_110 (Add)                   (None, 256, 256, 32) 0           batch_normalization_162[0][0]    \n",
      "                                                                 batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 256, 256, 32) 0           add_110[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 256, 256, 32) 128         activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 256, 256, 32) 9248        batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 256, 256, 32) 128         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 256, 256, 32) 0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 256, 256, 32) 9248        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 256, 256, 32) 128         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 256, 256, 32) 128         batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 256, 256, 32) 128         add_110[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_111 (Add)                   (None, 256, 256, 32) 0           batch_normalization_167[0][0]    \n",
      "                                                                 batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 256, 256, 32) 0           add_111[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 512, 512, 16) 4624        leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 512, 512, 16) 0           conv2d_transpose_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 512, 512, 16) 2320        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 512, 512, 16) 0           conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 512, 512, 16) 64          activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 512, 512, 16) 2320        batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 512, 512, 16) 64          conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 512, 512, 16) 0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 512, 512, 16) 2320        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 512, 512, 16) 64          conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 512, 512, 16) 64          batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 512, 512, 16) 64          conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_112 (Add)                   (None, 512, 512, 16) 0           batch_normalization_172[0][0]    \n",
      "                                                                 batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 512, 512, 16) 0           add_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 512, 512, 16) 64          activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 512, 512, 16) 2320        batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 512, 512, 16) 64          conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 512, 512, 16) 0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 512, 512, 16) 2320        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 512, 512, 16) 64          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 512, 512, 16) 64          batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 512, 512, 16) 64          add_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_113 (Add)                   (None, 512, 512, 16) 0           batch_normalization_177[0][0]    \n",
      "                                                                 batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 512, 512, 16) 0           add_113[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 512, 512, 16) 0           leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 512, 512, 1)  17          dropout_18[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 38,439,513\n",
      "Trainable params: 38,374,041\n",
      "Non-trainable params: 65,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "uexception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'uexception' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1af753edc3e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'uexception' is not defined"
     ]
    }
   ],
   "source": [
    "uexception.layers[121].output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(32), Dimension(32), Dimension(1024)])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uexception.layers[121].output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 16, 16, 512)\n",
      "(?, 16, 16, 512)\n",
      "(?, 16, 16, 512)\n",
      "(?, 16, 16, 512)\n",
      "The input block shape is (?, 16, 16, 512)\n",
      "The layer output is (?, 32, 32, 1024)\n",
      "The upconv output is shape (?, 32, 32, 256)\n",
      "The padding flag is set to False and padding is 1\n",
      "(?, 32, 32, 256)\n",
      "(?, 32, 32, 256)\n",
      "(?, 32, 32, 256)\n",
      "(?, 32, 32, 256)\n",
      "The input block shape is (?, 32, 32, 256)\n",
      "The layer output is (?, 64, 64, 728)\n",
      "The upconv output is shape (?, 64, 64, 128)\n",
      "The padding flag is set to False and padding is 1\n",
      "(?, 64, 64, 128)\n",
      "(?, 64, 64, 128)\n",
      "(?, 64, 64, 128)\n",
      "(?, 64, 64, 128)\n",
      "The input block shape is (?, 64, 64, 128)\n",
      "The layer output is (?, 127, 127, 256)\n",
      "The upconv output is shape (?, 128, 128, 64)\n",
      "The padding flag is set to True and padding is 1\n",
      "Inside zero padding\n",
      "Updated layer_output shape is Tensor(\"zero_padding2d_3/Pad:0\", shape=(?, 128, 128, 256), dtype=float32)\n",
      "(?, 128, 128, 64)\n",
      "(?, 128, 128, 64)\n",
      "(?, 128, 128, 64)\n",
      "(?, 128, 128, 64)\n",
      "The input block shape is (?, 128, 128, 64)\n",
      "The layer output is (?, 253, 253, 128)\n",
      "The upconv output is shape (?, 256, 256, 32)\n",
      "The padding flag is set to True and padding is 3\n",
      "Inside zero padding\n",
      "Updated layer_output shape is Tensor(\"zero_padding2d_4/Pad:0\", shape=(?, 256, 256, 128), dtype=float32)\n",
      "(?, 256, 256, 32)\n",
      "(?, 256, 256, 32)\n",
      "(?, 256, 256, 32)\n",
      "(?, 256, 256, 32)\n",
      "(?, 512, 512, 16)\n",
      "(?, 512, 512, 16)\n",
      "(?, 512, 512, 16)\n",
      "(?, 512, 512, 16)\n"
     ]
    }
   ],
   "source": [
    "mm = Unets(input_shape=(512,512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 24, 24, 512)\n",
      "(?, 24, 24, 512)\n",
      "(?, 24, 24, 512)\n",
      "(?, 24, 24, 512)\n",
      "The input block shape is (?, 24, 24, 512)\n",
      "The layer output is (?, 48, 48, 1024)\n",
      "The upconv output is shape (?, 48, 48, 256)\n",
      "The padding flag is set to False and padding is 1\n",
      "(?, 48, 48, 256)\n",
      "(?, 48, 48, 256)\n",
      "(?, 48, 48, 256)\n",
      "(?, 48, 48, 256)\n",
      "The input block shape is (?, 48, 48, 256)\n",
      "The layer output is (?, 96, 96, 728)\n",
      "The upconv output is shape (?, 96, 96, 128)\n",
      "The padding flag is set to False and padding is 1\n",
      "(?, 96, 96, 128)\n",
      "(?, 96, 96, 128)\n",
      "(?, 96, 96, 128)\n",
      "(?, 96, 96, 128)\n",
      "The input block shape is (?, 96, 96, 128)\n",
      "The layer output is (?, 191, 191, 256)\n",
      "The upconv output is shape (?, 192, 192, 64)\n",
      "The padding flag is set to True and padding is 1\n",
      "Inside zero padding\n",
      "Updated layer_output shape is Tensor(\"zero_padding2d_7/Pad:0\", shape=(?, 192, 192, 256), dtype=float32)\n",
      "(?, 192, 192, 64)\n",
      "(?, 192, 192, 64)\n",
      "(?, 192, 192, 64)\n",
      "(?, 192, 192, 64)\n",
      "The input block shape is (?, 192, 192, 64)\n",
      "The layer output is (?, 381, 381, 128)\n",
      "The upconv output is shape (?, 384, 384, 32)\n",
      "The padding flag is set to True and padding is 3\n",
      "Inside zero padding\n",
      "Updated layer_output shape is Tensor(\"zero_padding2d_8/Pad:0\", shape=(?, 384, 384, 128), dtype=float32)\n",
      "(?, 384, 384, 32)\n",
      "(?, 384, 384, 32)\n",
      "(?, 384, 384, 32)\n",
      "(?, 384, 384, 32)\n",
      "(?, 768, 768, 16)\n",
      "(?, 768, 768, 16)\n",
      "(?, 768, 768, 16)\n",
      "(?, 768, 768, 16)\n"
     ]
    }
   ],
   "source": [
    "mm1 = Unets(input_shape=(768,768,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 255, 255, 32) 864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 255, 255, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 255, 255, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 253, 253, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 253, 253, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 253, 253, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 253, 253, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 253, 253, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 253, 253, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 253, 253, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 253, 253, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 127, 127, 128 8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 127, 127, 128 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 127, 127, 128 512         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 127, 127, 128 0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 127, 127, 128 0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 127, 127, 256 33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 127, 127, 256 1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 127, 127, 256 0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 127, 127, 256 67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 127, 127, 256 1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 64, 64, 256)  32768       add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 64, 64, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 64, 64, 256)  1024        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 64, 64, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 64, 64, 256)  0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 64, 64, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 64, 64, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 64, 64, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 64, 64, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 64, 64, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 32, 32, 728)  186368      add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 32, 32, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 32, 32, 728)  2912        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 32, 32, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 32, 32, 728)  0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 32, 32, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 32, 32, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 32, 32, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 32, 32, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 32, 32, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 32, 32, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 32, 32, 728)  0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 32, 32, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 32, 32, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 32, 32, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 32, 32, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 32, 32, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 32, 32, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 32, 32, 728)  0           add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 32, 32, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 32, 32, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 32, 32, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 32, 32, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 32, 32, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 32, 32, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 32, 32, 728)  0           add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 32, 32, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 32, 32, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 32, 32, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 32, 32, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 32, 32, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 32, 32, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 32, 32, 728)  0           add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 32, 32, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 32, 32, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 32, 32, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 32, 32, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 32, 32, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 32, 32, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 32, 32, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 32, 32, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 32, 32, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 32, 32, 728)  0           add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 32, 32, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 32, 32, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 32, 32, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 32, 32, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 32, 32, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 32, 32, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 32, 32, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 32, 32, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 32, 32, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 32, 32, 728)  0           add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 32, 32, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 32, 32, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 32, 32, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 32, 32, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 32, 32, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 32, 32, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 32, 32, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 32, 32, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 32, 32, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 32, 32, 728)  0           add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 32, 32, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 32, 32, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 32, 32, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 32, 32, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 32, 32, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 32, 32, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 32, 32, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 32, 32, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 32, 32, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 32, 32, 728)  0           add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 32, 32, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 32, 32, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 32, 32, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 32, 32, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 32, 32, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 32, 32, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 1024) 0           leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 16, 16, 1024) 0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 16, 16, 512)  4719104     dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 512)  0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 16, 16, 512)  2048        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 16, 16, 512)  2359808     batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 16, 16, 512)  2048        conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 512)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 16, 16, 512)  2359808     activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 16, 16, 512)  2048        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 16, 16, 512)  2048        batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 16, 16, 512)  2048        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 16, 16, 512)  0           batch_normalization_106[0][0]    \n",
      "                                                                 batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 512)  0           add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 16, 16, 512)  2048        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 16, 16, 512)  2359808     batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 16, 16, 512)  2048        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 512)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 16, 16, 512)  2359808     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 16, 16, 512)  2048        conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 16, 16, 512)  2048        batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 16, 16, 512)  2048        add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 16, 16, 512)  0           batch_normalization_111[0][0]    \n",
      "                                                                 batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 16, 16, 512)  0           add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 32, 32, 256)  1179904     leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 1280) 0           conv2d_transpose_8[0][0]         \n",
      "                                                                 block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 1280) 0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 32, 32, 256)  2949376     dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 32, 32, 256)  0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 32, 32, 256)  1024        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 32, 32, 256)  590080      batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 32, 32, 256)  1024        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 32, 32, 256)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 32, 32, 256)  590080      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 32, 32, 256)  1024        conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 32, 32, 256)  1024        batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 32, 32, 256)  1024        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 32, 32, 256)  0           batch_normalization_116[0][0]    \n",
      "                                                                 batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 32, 32, 256)  0           add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 32, 32, 256)  1024        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 32, 32, 256)  590080      batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 32, 32, 256)  1024        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 32, 32, 256)  0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 32, 32, 256)  590080      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 32, 32, 256)  1024        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 32, 32, 256)  1024        batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 32, 32, 256)  1024        add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 32, 32, 256)  0           batch_normalization_121[0][0]    \n",
      "                                                                 batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 32, 32, 256)  0           add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 64, 64, 128)  295040      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 856)  0           conv2d_transpose_9[0][0]         \n",
      "                                                                 block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 64, 64, 856)  0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 64, 64, 128)  986240      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 64, 64, 128)  0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 64, 64, 128)  512         activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 64, 64, 128)  147584      batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 64, 64, 128)  512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 64, 64, 128)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 64, 64, 128)  147584      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 64, 64, 128)  512         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 64, 64, 128)  512         batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 64, 64, 128)  512         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 64, 64, 128)  0           batch_normalization_126[0][0]    \n",
      "                                                                 batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 64, 64, 128)  0           add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 64, 64, 128)  512         activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 64, 64, 128)  147584      batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 64, 64, 128)  512         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 64, 64, 128)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 64, 64, 128)  147584      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 64, 64, 128)  512         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 64, 64, 128)  512         batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 64, 64, 128)  512         add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 64, 64, 128)  0           batch_normalization_131[0][0]    \n",
      "                                                                 batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 64, 64, 128)  0           add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 128, 128, 64) 73792       leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 128, 128, 256 0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 128, 128, 320 0           conv2d_transpose_10[0][0]        \n",
      "                                                                 zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 128, 128, 320 0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 128, 128, 64) 184384      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 128, 128, 64) 0           conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 128, 128, 64) 256         activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 128, 128, 64) 36928       batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 128, 128, 64) 256         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 128, 128, 64) 0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 128, 128, 64) 36928       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 128, 128, 64) 256         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 128, 128, 64) 256         batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 128, 128, 64) 256         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 128, 128, 64) 0           batch_normalization_136[0][0]    \n",
      "                                                                 batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128, 128, 64) 0           add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 128, 128, 64) 256         activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 128, 128, 64) 36928       batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 128, 128, 64) 256         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 128, 128, 64) 0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 128, 128, 64) 36928       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 128, 128, 64) 256         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 128, 128, 64) 256         batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 128, 128, 64) 256         add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 128, 128, 64) 0           batch_normalization_141[0][0]    \n",
      "                                                                 batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 128, 128, 64) 0           add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 256, 256, 32) 18464       leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 256, 256, 128 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 256, 256, 160 0           conv2d_transpose_11[0][0]        \n",
      "                                                                 zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 256, 256, 160 0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 256, 256, 32) 46112       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 256, 256, 32) 0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 256, 256, 32) 128         activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 256, 256, 32) 9248        batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 256, 256, 32) 128         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 256, 256, 32) 0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 256, 256, 32) 9248        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 256, 256, 32) 128         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 256, 256, 32) 128         batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 256, 256, 32) 128         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 256, 256, 32) 0           batch_normalization_146[0][0]    \n",
      "                                                                 batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 256, 256, 32) 0           add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 256, 256, 32) 128         activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 256, 256, 32) 9248        batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 256, 256, 32) 128         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 256, 256, 32) 0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 256, 256, 32) 9248        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 256, 256, 32) 128         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 256, 256, 32) 128         batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 256, 256, 32) 128         add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 256, 256, 32) 0           batch_normalization_151[0][0]    \n",
      "                                                                 batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 256, 256, 32) 0           add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 512, 512, 16) 4624        leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 512, 512, 16) 0           conv2d_transpose_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 512, 512, 16) 2320        dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 512, 512, 16) 0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 512, 512, 16) 64          activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 512, 512, 16) 2320        batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 512, 512, 16) 64          conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 512, 512, 16) 0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 512, 512, 16) 2320        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 512, 512, 16) 64          conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 512, 512, 16) 64          batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 512, 512, 16) 64          conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 512, 512, 16) 0           batch_normalization_156[0][0]    \n",
      "                                                                 batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 512, 512, 16) 0           add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 512, 512, 16) 64          activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 512, 512, 16) 2320        batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 512, 512, 16) 64          conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 512, 512, 16) 0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 512, 512, 16) 2320        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 512, 512, 16) 64          conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 512, 512, 16) 64          batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 512, 512, 16) 64          add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, 512, 512, 16) 0           batch_normalization_161[0][0]    \n",
      "                                                                 batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 512, 512, 16) 0           add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 512, 512, 16) 0           leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 512, 512, 1)  17          dropout_16[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 38,439,513\n",
      "Trainable params: 38,374,041\n",
      "Non-trainable params: 65,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = tf.random_normal((1,3,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(3), Dimension(3), Dimension(3)])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZeroPadding2D(padding=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "51879936/51877672 [==============================] - 257s 5us/step\n"
     ]
    }
   ],
   "source": [
    "m1 = Densenet(input_shape=(512,512,3),weights='imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index is 0 , the name of the layer is input_4, the output is (?, 512, 512, 3)\n",
      "The index is 1 , the name of the layer is zero_padding2d_5, the output is (?, 518, 518, 3)\n",
      "The index is 2 , the name of the layer is conv1/conv, the output is (?, 256, 256, 64)\n",
      "The index is 3 , the name of the layer is conv1/bn, the output is (?, 256, 256, 64)\n",
      "The index is 4 , the name of the layer is conv1/relu, the output is (?, 256, 256, 64)\n",
      "The index is 5 , the name of the layer is zero_padding2d_6, the output is (?, 258, 258, 64)\n",
      "The index is 6 , the name of the layer is pool1, the output is (?, 128, 128, 64)\n",
      "The index is 7 , the name of the layer is conv2_block1_0_bn, the output is (?, 128, 128, 64)\n",
      "The index is 8 , the name of the layer is conv2_block1_0_relu, the output is (?, 128, 128, 64)\n",
      "The index is 9 , the name of the layer is conv2_block1_1_conv, the output is (?, 128, 128, 128)\n",
      "The index is 10 , the name of the layer is conv2_block1_1_bn, the output is (?, 128, 128, 128)\n",
      "The index is 11 , the name of the layer is conv2_block1_1_relu, the output is (?, 128, 128, 128)\n",
      "The index is 12 , the name of the layer is conv2_block1_2_conv, the output is (?, 128, 128, 32)\n",
      "The index is 13 , the name of the layer is conv2_block1_concat, the output is (?, 128, 128, 96)\n",
      "The index is 14 , the name of the layer is conv2_block2_0_bn, the output is (?, 128, 128, 96)\n",
      "The index is 15 , the name of the layer is conv2_block2_0_relu, the output is (?, 128, 128, 96)\n",
      "The index is 16 , the name of the layer is conv2_block2_1_conv, the output is (?, 128, 128, 128)\n",
      "The index is 17 , the name of the layer is conv2_block2_1_bn, the output is (?, 128, 128, 128)\n",
      "The index is 18 , the name of the layer is conv2_block2_1_relu, the output is (?, 128, 128, 128)\n",
      "The index is 19 , the name of the layer is conv2_block2_2_conv, the output is (?, 128, 128, 32)\n",
      "The index is 20 , the name of the layer is conv2_block2_concat, the output is (?, 128, 128, 128)\n",
      "The index is 21 , the name of the layer is conv2_block3_0_bn, the output is (?, 128, 128, 128)\n",
      "The index is 22 , the name of the layer is conv2_block3_0_relu, the output is (?, 128, 128, 128)\n",
      "The index is 23 , the name of the layer is conv2_block3_1_conv, the output is (?, 128, 128, 128)\n",
      "The index is 24 , the name of the layer is conv2_block3_1_bn, the output is (?, 128, 128, 128)\n",
      "The index is 25 , the name of the layer is conv2_block3_1_relu, the output is (?, 128, 128, 128)\n",
      "The index is 26 , the name of the layer is conv2_block3_2_conv, the output is (?, 128, 128, 32)\n",
      "The index is 27 , the name of the layer is conv2_block3_concat, the output is (?, 128, 128, 160)\n",
      "The index is 28 , the name of the layer is conv2_block4_0_bn, the output is (?, 128, 128, 160)\n",
      "The index is 29 , the name of the layer is conv2_block4_0_relu, the output is (?, 128, 128, 160)\n",
      "The index is 30 , the name of the layer is conv2_block4_1_conv, the output is (?, 128, 128, 128)\n",
      "The index is 31 , the name of the layer is conv2_block4_1_bn, the output is (?, 128, 128, 128)\n",
      "The index is 32 , the name of the layer is conv2_block4_1_relu, the output is (?, 128, 128, 128)\n",
      "The index is 33 , the name of the layer is conv2_block4_2_conv, the output is (?, 128, 128, 32)\n",
      "The index is 34 , the name of the layer is conv2_block4_concat, the output is (?, 128, 128, 192)\n",
      "The index is 35 , the name of the layer is conv2_block5_0_bn, the output is (?, 128, 128, 192)\n",
      "The index is 36 , the name of the layer is conv2_block5_0_relu, the output is (?, 128, 128, 192)\n",
      "The index is 37 , the name of the layer is conv2_block5_1_conv, the output is (?, 128, 128, 128)\n",
      "The index is 38 , the name of the layer is conv2_block5_1_bn, the output is (?, 128, 128, 128)\n",
      "The index is 39 , the name of the layer is conv2_block5_1_relu, the output is (?, 128, 128, 128)\n",
      "The index is 40 , the name of the layer is conv2_block5_2_conv, the output is (?, 128, 128, 32)\n",
      "The index is 41 , the name of the layer is conv2_block5_concat, the output is (?, 128, 128, 224)\n",
      "The index is 42 , the name of the layer is conv2_block6_0_bn, the output is (?, 128, 128, 224)\n",
      "The index is 43 , the name of the layer is conv2_block6_0_relu, the output is (?, 128, 128, 224)\n",
      "The index is 44 , the name of the layer is conv2_block6_1_conv, the output is (?, 128, 128, 128)\n",
      "The index is 45 , the name of the layer is conv2_block6_1_bn, the output is (?, 128, 128, 128)\n",
      "The index is 46 , the name of the layer is conv2_block6_1_relu, the output is (?, 128, 128, 128)\n",
      "The index is 47 , the name of the layer is conv2_block6_2_conv, the output is (?, 128, 128, 32)\n",
      "The index is 48 , the name of the layer is conv2_block6_concat, the output is (?, 128, 128, 256)\n",
      "The index is 49 , the name of the layer is pool2_bn, the output is (?, 128, 128, 256)\n",
      "The index is 50 , the name of the layer is pool2_relu, the output is (?, 128, 128, 256)\n",
      "The index is 51 , the name of the layer is pool2_conv, the output is (?, 128, 128, 128)\n",
      "The index is 52 , the name of the layer is pool2_pool, the output is (?, 64, 64, 128)\n",
      "The index is 53 , the name of the layer is conv3_block1_0_bn, the output is (?, 64, 64, 128)\n",
      "The index is 54 , the name of the layer is conv3_block1_0_relu, the output is (?, 64, 64, 128)\n",
      "The index is 55 , the name of the layer is conv3_block1_1_conv, the output is (?, 64, 64, 128)\n",
      "The index is 56 , the name of the layer is conv3_block1_1_bn, the output is (?, 64, 64, 128)\n",
      "The index is 57 , the name of the layer is conv3_block1_1_relu, the output is (?, 64, 64, 128)\n",
      "The index is 58 , the name of the layer is conv3_block1_2_conv, the output is (?, 64, 64, 32)\n",
      "The index is 59 , the name of the layer is conv3_block1_concat, the output is (?, 64, 64, 160)\n",
      "The index is 60 , the name of the layer is conv3_block2_0_bn, the output is (?, 64, 64, 160)\n",
      "The index is 61 , the name of the layer is conv3_block2_0_relu, the output is (?, 64, 64, 160)\n",
      "The index is 62 , the name of the layer is conv3_block2_1_conv, the output is (?, 64, 64, 128)\n",
      "The index is 63 , the name of the layer is conv3_block2_1_bn, the output is (?, 64, 64, 128)\n",
      "The index is 64 , the name of the layer is conv3_block2_1_relu, the output is (?, 64, 64, 128)\n",
      "The index is 65 , the name of the layer is conv3_block2_2_conv, the output is (?, 64, 64, 32)\n",
      "The index is 66 , the name of the layer is conv3_block2_concat, the output is (?, 64, 64, 192)\n",
      "The index is 67 , the name of the layer is conv3_block3_0_bn, the output is (?, 64, 64, 192)\n",
      "The index is 68 , the name of the layer is conv3_block3_0_relu, the output is (?, 64, 64, 192)\n",
      "The index is 69 , the name of the layer is conv3_block3_1_conv, the output is (?, 64, 64, 128)\n",
      "The index is 70 , the name of the layer is conv3_block3_1_bn, the output is (?, 64, 64, 128)\n",
      "The index is 71 , the name of the layer is conv3_block3_1_relu, the output is (?, 64, 64, 128)\n",
      "The index is 72 , the name of the layer is conv3_block3_2_conv, the output is (?, 64, 64, 32)\n",
      "The index is 73 , the name of the layer is conv3_block3_concat, the output is (?, 64, 64, 224)\n",
      "The index is 74 , the name of the layer is conv3_block4_0_bn, the output is (?, 64, 64, 224)\n",
      "The index is 75 , the name of the layer is conv3_block4_0_relu, the output is (?, 64, 64, 224)\n",
      "The index is 76 , the name of the layer is conv3_block4_1_conv, the output is (?, 64, 64, 128)\n",
      "The index is 77 , the name of the layer is conv3_block4_1_bn, the output is (?, 64, 64, 128)\n",
      "The index is 78 , the name of the layer is conv3_block4_1_relu, the output is (?, 64, 64, 128)\n",
      "The index is 79 , the name of the layer is conv3_block4_2_conv, the output is (?, 64, 64, 32)\n",
      "The index is 80 , the name of the layer is conv3_block4_concat, the output is (?, 64, 64, 256)\n",
      "The index is 81 , the name of the layer is conv3_block5_0_bn, the output is (?, 64, 64, 256)\n",
      "The index is 82 , the name of the layer is conv3_block5_0_relu, the output is (?, 64, 64, 256)\n",
      "The index is 83 , the name of the layer is conv3_block5_1_conv, the output is (?, 64, 64, 128)\n",
      "The index is 84 , the name of the layer is conv3_block5_1_bn, the output is (?, 64, 64, 128)\n",
      "The index is 85 , the name of the layer is conv3_block5_1_relu, the output is (?, 64, 64, 128)\n",
      "The index is 86 , the name of the layer is conv3_block5_2_conv, the output is (?, 64, 64, 32)\n",
      "The index is 87 , the name of the layer is conv3_block5_concat, the output is (?, 64, 64, 288)\n",
      "The index is 88 , the name of the layer is conv3_block6_0_bn, the output is (?, 64, 64, 288)\n",
      "The index is 89 , the name of the layer is conv3_block6_0_relu, the output is (?, 64, 64, 288)\n",
      "The index is 90 , the name of the layer is conv3_block6_1_conv, the output is (?, 64, 64, 128)\n",
      "The index is 91 , the name of the layer is conv3_block6_1_bn, the output is (?, 64, 64, 128)\n",
      "The index is 92 , the name of the layer is conv3_block6_1_relu, the output is (?, 64, 64, 128)\n",
      "The index is 93 , the name of the layer is conv3_block6_2_conv, the output is (?, 64, 64, 32)\n",
      "The index is 94 , the name of the layer is conv3_block6_concat, the output is (?, 64, 64, 320)\n",
      "The index is 95 , the name of the layer is conv3_block7_0_bn, the output is (?, 64, 64, 320)\n",
      "The index is 96 , the name of the layer is conv3_block7_0_relu, the output is (?, 64, 64, 320)\n",
      "The index is 97 , the name of the layer is conv3_block7_1_conv, the output is (?, 64, 64, 128)\n",
      "The index is 98 , the name of the layer is conv3_block7_1_bn, the output is (?, 64, 64, 128)\n",
      "The index is 99 , the name of the layer is conv3_block7_1_relu, the output is (?, 64, 64, 128)\n",
      "The index is 100 , the name of the layer is conv3_block7_2_conv, the output is (?, 64, 64, 32)\n",
      "The index is 101 , the name of the layer is conv3_block7_concat, the output is (?, 64, 64, 352)\n",
      "The index is 102 , the name of the layer is conv3_block8_0_bn, the output is (?, 64, 64, 352)\n",
      "The index is 103 , the name of the layer is conv3_block8_0_relu, the output is (?, 64, 64, 352)\n",
      "The index is 104 , the name of the layer is conv3_block8_1_conv, the output is (?, 64, 64, 128)\n",
      "The index is 105 , the name of the layer is conv3_block8_1_bn, the output is (?, 64, 64, 128)\n",
      "The index is 106 , the name of the layer is conv3_block8_1_relu, the output is (?, 64, 64, 128)\n",
      "The index is 107 , the name of the layer is conv3_block8_2_conv, the output is (?, 64, 64, 32)\n",
      "The index is 108 , the name of the layer is conv3_block8_concat, the output is (?, 64, 64, 384)\n",
      "The index is 109 , the name of the layer is conv3_block9_0_bn, the output is (?, 64, 64, 384)\n",
      "The index is 110 , the name of the layer is conv3_block9_0_relu, the output is (?, 64, 64, 384)\n",
      "The index is 111 , the name of the layer is conv3_block9_1_conv, the output is (?, 64, 64, 128)\n",
      "The index is 112 , the name of the layer is conv3_block9_1_bn, the output is (?, 64, 64, 128)\n",
      "The index is 113 , the name of the layer is conv3_block9_1_relu, the output is (?, 64, 64, 128)\n",
      "The index is 114 , the name of the layer is conv3_block9_2_conv, the output is (?, 64, 64, 32)\n",
      "The index is 115 , the name of the layer is conv3_block9_concat, the output is (?, 64, 64, 416)\n",
      "The index is 116 , the name of the layer is conv3_block10_0_bn, the output is (?, 64, 64, 416)\n",
      "The index is 117 , the name of the layer is conv3_block10_0_relu, the output is (?, 64, 64, 416)\n",
      "The index is 118 , the name of the layer is conv3_block10_1_conv, the output is (?, 64, 64, 128)\n",
      "The index is 119 , the name of the layer is conv3_block10_1_bn, the output is (?, 64, 64, 128)\n",
      "The index is 120 , the name of the layer is conv3_block10_1_relu, the output is (?, 64, 64, 128)\n",
      "The index is 121 , the name of the layer is conv3_block10_2_conv, the output is (?, 64, 64, 32)\n",
      "The index is 122 , the name of the layer is conv3_block10_concat, the output is (?, 64, 64, 448)\n",
      "The index is 123 , the name of the layer is conv3_block11_0_bn, the output is (?, 64, 64, 448)\n",
      "The index is 124 , the name of the layer is conv3_block11_0_relu, the output is (?, 64, 64, 448)\n",
      "The index is 125 , the name of the layer is conv3_block11_1_conv, the output is (?, 64, 64, 128)\n",
      "The index is 126 , the name of the layer is conv3_block11_1_bn, the output is (?, 64, 64, 128)\n",
      "The index is 127 , the name of the layer is conv3_block11_1_relu, the output is (?, 64, 64, 128)\n",
      "The index is 128 , the name of the layer is conv3_block11_2_conv, the output is (?, 64, 64, 32)\n",
      "The index is 129 , the name of the layer is conv3_block11_concat, the output is (?, 64, 64, 480)\n",
      "The index is 130 , the name of the layer is conv3_block12_0_bn, the output is (?, 64, 64, 480)\n",
      "The index is 131 , the name of the layer is conv3_block12_0_relu, the output is (?, 64, 64, 480)\n",
      "The index is 132 , the name of the layer is conv3_block12_1_conv, the output is (?, 64, 64, 128)\n",
      "The index is 133 , the name of the layer is conv3_block12_1_bn, the output is (?, 64, 64, 128)\n",
      "The index is 134 , the name of the layer is conv3_block12_1_relu, the output is (?, 64, 64, 128)\n",
      "The index is 135 , the name of the layer is conv3_block12_2_conv, the output is (?, 64, 64, 32)\n",
      "The index is 136 , the name of the layer is conv3_block12_concat, the output is (?, 64, 64, 512)\n",
      "The index is 137 , the name of the layer is pool3_bn, the output is (?, 64, 64, 512)\n",
      "The index is 138 , the name of the layer is pool3_relu, the output is (?, 64, 64, 512)\n",
      "The index is 139 , the name of the layer is pool3_conv, the output is (?, 64, 64, 256)\n",
      "The index is 140 , the name of the layer is pool3_pool, the output is (?, 32, 32, 256)\n",
      "The index is 141 , the name of the layer is conv4_block1_0_bn, the output is (?, 32, 32, 256)\n",
      "The index is 142 , the name of the layer is conv4_block1_0_relu, the output is (?, 32, 32, 256)\n",
      "The index is 143 , the name of the layer is conv4_block1_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 144 , the name of the layer is conv4_block1_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 145 , the name of the layer is conv4_block1_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 146 , the name of the layer is conv4_block1_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 147 , the name of the layer is conv4_block1_concat, the output is (?, 32, 32, 288)\n",
      "The index is 148 , the name of the layer is conv4_block2_0_bn, the output is (?, 32, 32, 288)\n",
      "The index is 149 , the name of the layer is conv4_block2_0_relu, the output is (?, 32, 32, 288)\n",
      "The index is 150 , the name of the layer is conv4_block2_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 151 , the name of the layer is conv4_block2_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 152 , the name of the layer is conv4_block2_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 153 , the name of the layer is conv4_block2_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 154 , the name of the layer is conv4_block2_concat, the output is (?, 32, 32, 320)\n",
      "The index is 155 , the name of the layer is conv4_block3_0_bn, the output is (?, 32, 32, 320)\n",
      "The index is 156 , the name of the layer is conv4_block3_0_relu, the output is (?, 32, 32, 320)\n",
      "The index is 157 , the name of the layer is conv4_block3_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 158 , the name of the layer is conv4_block3_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 159 , the name of the layer is conv4_block3_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 160 , the name of the layer is conv4_block3_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 161 , the name of the layer is conv4_block3_concat, the output is (?, 32, 32, 352)\n",
      "The index is 162 , the name of the layer is conv4_block4_0_bn, the output is (?, 32, 32, 352)\n",
      "The index is 163 , the name of the layer is conv4_block4_0_relu, the output is (?, 32, 32, 352)\n",
      "The index is 164 , the name of the layer is conv4_block4_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 165 , the name of the layer is conv4_block4_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 166 , the name of the layer is conv4_block4_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 167 , the name of the layer is conv4_block4_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 168 , the name of the layer is conv4_block4_concat, the output is (?, 32, 32, 384)\n",
      "The index is 169 , the name of the layer is conv4_block5_0_bn, the output is (?, 32, 32, 384)\n",
      "The index is 170 , the name of the layer is conv4_block5_0_relu, the output is (?, 32, 32, 384)\n",
      "The index is 171 , the name of the layer is conv4_block5_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 172 , the name of the layer is conv4_block5_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 173 , the name of the layer is conv4_block5_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 174 , the name of the layer is conv4_block5_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 175 , the name of the layer is conv4_block5_concat, the output is (?, 32, 32, 416)\n",
      "The index is 176 , the name of the layer is conv4_block6_0_bn, the output is (?, 32, 32, 416)\n",
      "The index is 177 , the name of the layer is conv4_block6_0_relu, the output is (?, 32, 32, 416)\n",
      "The index is 178 , the name of the layer is conv4_block6_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 179 , the name of the layer is conv4_block6_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 180 , the name of the layer is conv4_block6_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 181 , the name of the layer is conv4_block6_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 182 , the name of the layer is conv4_block6_concat, the output is (?, 32, 32, 448)\n",
      "The index is 183 , the name of the layer is conv4_block7_0_bn, the output is (?, 32, 32, 448)\n",
      "The index is 184 , the name of the layer is conv4_block7_0_relu, the output is (?, 32, 32, 448)\n",
      "The index is 185 , the name of the layer is conv4_block7_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 186 , the name of the layer is conv4_block7_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 187 , the name of the layer is conv4_block7_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 188 , the name of the layer is conv4_block7_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 189 , the name of the layer is conv4_block7_concat, the output is (?, 32, 32, 480)\n",
      "The index is 190 , the name of the layer is conv4_block8_0_bn, the output is (?, 32, 32, 480)\n",
      "The index is 191 , the name of the layer is conv4_block8_0_relu, the output is (?, 32, 32, 480)\n",
      "The index is 192 , the name of the layer is conv4_block8_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 193 , the name of the layer is conv4_block8_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 194 , the name of the layer is conv4_block8_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 195 , the name of the layer is conv4_block8_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 196 , the name of the layer is conv4_block8_concat, the output is (?, 32, 32, 512)\n",
      "The index is 197 , the name of the layer is conv4_block9_0_bn, the output is (?, 32, 32, 512)\n",
      "The index is 198 , the name of the layer is conv4_block9_0_relu, the output is (?, 32, 32, 512)\n",
      "The index is 199 , the name of the layer is conv4_block9_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 200 , the name of the layer is conv4_block9_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 201 , the name of the layer is conv4_block9_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 202 , the name of the layer is conv4_block9_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 203 , the name of the layer is conv4_block9_concat, the output is (?, 32, 32, 544)\n",
      "The index is 204 , the name of the layer is conv4_block10_0_bn, the output is (?, 32, 32, 544)\n",
      "The index is 205 , the name of the layer is conv4_block10_0_relu, the output is (?, 32, 32, 544)\n",
      "The index is 206 , the name of the layer is conv4_block10_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 207 , the name of the layer is conv4_block10_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 208 , the name of the layer is conv4_block10_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 209 , the name of the layer is conv4_block10_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 210 , the name of the layer is conv4_block10_concat, the output is (?, 32, 32, 576)\n",
      "The index is 211 , the name of the layer is conv4_block11_0_bn, the output is (?, 32, 32, 576)\n",
      "The index is 212 , the name of the layer is conv4_block11_0_relu, the output is (?, 32, 32, 576)\n",
      "The index is 213 , the name of the layer is conv4_block11_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 214 , the name of the layer is conv4_block11_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 215 , the name of the layer is conv4_block11_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 216 , the name of the layer is conv4_block11_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 217 , the name of the layer is conv4_block11_concat, the output is (?, 32, 32, 608)\n",
      "The index is 218 , the name of the layer is conv4_block12_0_bn, the output is (?, 32, 32, 608)\n",
      "The index is 219 , the name of the layer is conv4_block12_0_relu, the output is (?, 32, 32, 608)\n",
      "The index is 220 , the name of the layer is conv4_block12_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 221 , the name of the layer is conv4_block12_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 222 , the name of the layer is conv4_block12_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 223 , the name of the layer is conv4_block12_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 224 , the name of the layer is conv4_block12_concat, the output is (?, 32, 32, 640)\n",
      "The index is 225 , the name of the layer is conv4_block13_0_bn, the output is (?, 32, 32, 640)\n",
      "The index is 226 , the name of the layer is conv4_block13_0_relu, the output is (?, 32, 32, 640)\n",
      "The index is 227 , the name of the layer is conv4_block13_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 228 , the name of the layer is conv4_block13_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 229 , the name of the layer is conv4_block13_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 230 , the name of the layer is conv4_block13_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 231 , the name of the layer is conv4_block13_concat, the output is (?, 32, 32, 672)\n",
      "The index is 232 , the name of the layer is conv4_block14_0_bn, the output is (?, 32, 32, 672)\n",
      "The index is 233 , the name of the layer is conv4_block14_0_relu, the output is (?, 32, 32, 672)\n",
      "The index is 234 , the name of the layer is conv4_block14_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 235 , the name of the layer is conv4_block14_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 236 , the name of the layer is conv4_block14_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 237 , the name of the layer is conv4_block14_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 238 , the name of the layer is conv4_block14_concat, the output is (?, 32, 32, 704)\n",
      "The index is 239 , the name of the layer is conv4_block15_0_bn, the output is (?, 32, 32, 704)\n",
      "The index is 240 , the name of the layer is conv4_block15_0_relu, the output is (?, 32, 32, 704)\n",
      "The index is 241 , the name of the layer is conv4_block15_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 242 , the name of the layer is conv4_block15_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 243 , the name of the layer is conv4_block15_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 244 , the name of the layer is conv4_block15_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 245 , the name of the layer is conv4_block15_concat, the output is (?, 32, 32, 736)\n",
      "The index is 246 , the name of the layer is conv4_block16_0_bn, the output is (?, 32, 32, 736)\n",
      "The index is 247 , the name of the layer is conv4_block16_0_relu, the output is (?, 32, 32, 736)\n",
      "The index is 248 , the name of the layer is conv4_block16_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 249 , the name of the layer is conv4_block16_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 250 , the name of the layer is conv4_block16_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 251 , the name of the layer is conv4_block16_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 252 , the name of the layer is conv4_block16_concat, the output is (?, 32, 32, 768)\n",
      "The index is 253 , the name of the layer is conv4_block17_0_bn, the output is (?, 32, 32, 768)\n",
      "The index is 254 , the name of the layer is conv4_block17_0_relu, the output is (?, 32, 32, 768)\n",
      "The index is 255 , the name of the layer is conv4_block17_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 256 , the name of the layer is conv4_block17_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 257 , the name of the layer is conv4_block17_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 258 , the name of the layer is conv4_block17_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 259 , the name of the layer is conv4_block17_concat, the output is (?, 32, 32, 800)\n",
      "The index is 260 , the name of the layer is conv4_block18_0_bn, the output is (?, 32, 32, 800)\n",
      "The index is 261 , the name of the layer is conv4_block18_0_relu, the output is (?, 32, 32, 800)\n",
      "The index is 262 , the name of the layer is conv4_block18_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 263 , the name of the layer is conv4_block18_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 264 , the name of the layer is conv4_block18_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 265 , the name of the layer is conv4_block18_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 266 , the name of the layer is conv4_block18_concat, the output is (?, 32, 32, 832)\n",
      "The index is 267 , the name of the layer is conv4_block19_0_bn, the output is (?, 32, 32, 832)\n",
      "The index is 268 , the name of the layer is conv4_block19_0_relu, the output is (?, 32, 32, 832)\n",
      "The index is 269 , the name of the layer is conv4_block19_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 270 , the name of the layer is conv4_block19_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 271 , the name of the layer is conv4_block19_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 272 , the name of the layer is conv4_block19_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 273 , the name of the layer is conv4_block19_concat, the output is (?, 32, 32, 864)\n",
      "The index is 274 , the name of the layer is conv4_block20_0_bn, the output is (?, 32, 32, 864)\n",
      "The index is 275 , the name of the layer is conv4_block20_0_relu, the output is (?, 32, 32, 864)\n",
      "The index is 276 , the name of the layer is conv4_block20_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 277 , the name of the layer is conv4_block20_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 278 , the name of the layer is conv4_block20_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 279 , the name of the layer is conv4_block20_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 280 , the name of the layer is conv4_block20_concat, the output is (?, 32, 32, 896)\n",
      "The index is 281 , the name of the layer is conv4_block21_0_bn, the output is (?, 32, 32, 896)\n",
      "The index is 282 , the name of the layer is conv4_block21_0_relu, the output is (?, 32, 32, 896)\n",
      "The index is 283 , the name of the layer is conv4_block21_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 284 , the name of the layer is conv4_block21_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 285 , the name of the layer is conv4_block21_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 286 , the name of the layer is conv4_block21_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 287 , the name of the layer is conv4_block21_concat, the output is (?, 32, 32, 928)\n",
      "The index is 288 , the name of the layer is conv4_block22_0_bn, the output is (?, 32, 32, 928)\n",
      "The index is 289 , the name of the layer is conv4_block22_0_relu, the output is (?, 32, 32, 928)\n",
      "The index is 290 , the name of the layer is conv4_block22_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 291 , the name of the layer is conv4_block22_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 292 , the name of the layer is conv4_block22_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 293 , the name of the layer is conv4_block22_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 294 , the name of the layer is conv4_block22_concat, the output is (?, 32, 32, 960)\n",
      "The index is 295 , the name of the layer is conv4_block23_0_bn, the output is (?, 32, 32, 960)\n",
      "The index is 296 , the name of the layer is conv4_block23_0_relu, the output is (?, 32, 32, 960)\n",
      "The index is 297 , the name of the layer is conv4_block23_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 298 , the name of the layer is conv4_block23_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 299 , the name of the layer is conv4_block23_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 300 , the name of the layer is conv4_block23_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 301 , the name of the layer is conv4_block23_concat, the output is (?, 32, 32, 992)\n",
      "The index is 302 , the name of the layer is conv4_block24_0_bn, the output is (?, 32, 32, 992)\n",
      "The index is 303 , the name of the layer is conv4_block24_0_relu, the output is (?, 32, 32, 992)\n",
      "The index is 304 , the name of the layer is conv4_block24_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 305 , the name of the layer is conv4_block24_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 306 , the name of the layer is conv4_block24_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 307 , the name of the layer is conv4_block24_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 308 , the name of the layer is conv4_block24_concat, the output is (?, 32, 32, 1024)\n",
      "The index is 309 , the name of the layer is conv4_block25_0_bn, the output is (?, 32, 32, 1024)\n",
      "The index is 310 , the name of the layer is conv4_block25_0_relu, the output is (?, 32, 32, 1024)\n",
      "The index is 311 , the name of the layer is conv4_block25_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 312 , the name of the layer is conv4_block25_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 313 , the name of the layer is conv4_block25_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 314 , the name of the layer is conv4_block25_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 315 , the name of the layer is conv4_block25_concat, the output is (?, 32, 32, 1056)\n",
      "The index is 316 , the name of the layer is conv4_block26_0_bn, the output is (?, 32, 32, 1056)\n",
      "The index is 317 , the name of the layer is conv4_block26_0_relu, the output is (?, 32, 32, 1056)\n",
      "The index is 318 , the name of the layer is conv4_block26_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 319 , the name of the layer is conv4_block26_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 320 , the name of the layer is conv4_block26_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 321 , the name of the layer is conv4_block26_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 322 , the name of the layer is conv4_block26_concat, the output is (?, 32, 32, 1088)\n",
      "The index is 323 , the name of the layer is conv4_block27_0_bn, the output is (?, 32, 32, 1088)\n",
      "The index is 324 , the name of the layer is conv4_block27_0_relu, the output is (?, 32, 32, 1088)\n",
      "The index is 325 , the name of the layer is conv4_block27_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 326 , the name of the layer is conv4_block27_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 327 , the name of the layer is conv4_block27_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 328 , the name of the layer is conv4_block27_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 329 , the name of the layer is conv4_block27_concat, the output is (?, 32, 32, 1120)\n",
      "The index is 330 , the name of the layer is conv4_block28_0_bn, the output is (?, 32, 32, 1120)\n",
      "The index is 331 , the name of the layer is conv4_block28_0_relu, the output is (?, 32, 32, 1120)\n",
      "The index is 332 , the name of the layer is conv4_block28_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 333 , the name of the layer is conv4_block28_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 334 , the name of the layer is conv4_block28_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 335 , the name of the layer is conv4_block28_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 336 , the name of the layer is conv4_block28_concat, the output is (?, 32, 32, 1152)\n",
      "The index is 337 , the name of the layer is conv4_block29_0_bn, the output is (?, 32, 32, 1152)\n",
      "The index is 338 , the name of the layer is conv4_block29_0_relu, the output is (?, 32, 32, 1152)\n",
      "The index is 339 , the name of the layer is conv4_block29_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 340 , the name of the layer is conv4_block29_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 341 , the name of the layer is conv4_block29_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 342 , the name of the layer is conv4_block29_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 343 , the name of the layer is conv4_block29_concat, the output is (?, 32, 32, 1184)\n",
      "The index is 344 , the name of the layer is conv4_block30_0_bn, the output is (?, 32, 32, 1184)\n",
      "The index is 345 , the name of the layer is conv4_block30_0_relu, the output is (?, 32, 32, 1184)\n",
      "The index is 346 , the name of the layer is conv4_block30_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 347 , the name of the layer is conv4_block30_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 348 , the name of the layer is conv4_block30_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 349 , the name of the layer is conv4_block30_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 350 , the name of the layer is conv4_block30_concat, the output is (?, 32, 32, 1216)\n",
      "The index is 351 , the name of the layer is conv4_block31_0_bn, the output is (?, 32, 32, 1216)\n",
      "The index is 352 , the name of the layer is conv4_block31_0_relu, the output is (?, 32, 32, 1216)\n",
      "The index is 353 , the name of the layer is conv4_block31_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 354 , the name of the layer is conv4_block31_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 355 , the name of the layer is conv4_block31_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 356 , the name of the layer is conv4_block31_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 357 , the name of the layer is conv4_block31_concat, the output is (?, 32, 32, 1248)\n",
      "The index is 358 , the name of the layer is conv4_block32_0_bn, the output is (?, 32, 32, 1248)\n",
      "The index is 359 , the name of the layer is conv4_block32_0_relu, the output is (?, 32, 32, 1248)\n",
      "The index is 360 , the name of the layer is conv4_block32_1_conv, the output is (?, 32, 32, 128)\n",
      "The index is 361 , the name of the layer is conv4_block32_1_bn, the output is (?, 32, 32, 128)\n",
      "The index is 362 , the name of the layer is conv4_block32_1_relu, the output is (?, 32, 32, 128)\n",
      "The index is 363 , the name of the layer is conv4_block32_2_conv, the output is (?, 32, 32, 32)\n",
      "The index is 364 , the name of the layer is conv4_block32_concat, the output is (?, 32, 32, 1280)\n",
      "The index is 365 , the name of the layer is pool4_bn, the output is (?, 32, 32, 1280)\n",
      "The index is 366 , the name of the layer is pool4_relu, the output is (?, 32, 32, 1280)\n",
      "The index is 367 , the name of the layer is pool4_conv, the output is (?, 32, 32, 640)\n",
      "The index is 368 , the name of the layer is pool4_pool, the output is (?, 16, 16, 640)\n",
      "The index is 369 , the name of the layer is conv5_block1_0_bn, the output is (?, 16, 16, 640)\n",
      "The index is 370 , the name of the layer is conv5_block1_0_relu, the output is (?, 16, 16, 640)\n",
      "The index is 371 , the name of the layer is conv5_block1_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 372 , the name of the layer is conv5_block1_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 373 , the name of the layer is conv5_block1_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 374 , the name of the layer is conv5_block1_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 375 , the name of the layer is conv5_block1_concat, the output is (?, 16, 16, 672)\n",
      "The index is 376 , the name of the layer is conv5_block2_0_bn, the output is (?, 16, 16, 672)\n",
      "The index is 377 , the name of the layer is conv5_block2_0_relu, the output is (?, 16, 16, 672)\n",
      "The index is 378 , the name of the layer is conv5_block2_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 379 , the name of the layer is conv5_block2_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 380 , the name of the layer is conv5_block2_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 381 , the name of the layer is conv5_block2_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 382 , the name of the layer is conv5_block2_concat, the output is (?, 16, 16, 704)\n",
      "The index is 383 , the name of the layer is conv5_block3_0_bn, the output is (?, 16, 16, 704)\n",
      "The index is 384 , the name of the layer is conv5_block3_0_relu, the output is (?, 16, 16, 704)\n",
      "The index is 385 , the name of the layer is conv5_block3_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 386 , the name of the layer is conv5_block3_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 387 , the name of the layer is conv5_block3_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 388 , the name of the layer is conv5_block3_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 389 , the name of the layer is conv5_block3_concat, the output is (?, 16, 16, 736)\n",
      "The index is 390 , the name of the layer is conv5_block4_0_bn, the output is (?, 16, 16, 736)\n",
      "The index is 391 , the name of the layer is conv5_block4_0_relu, the output is (?, 16, 16, 736)\n",
      "The index is 392 , the name of the layer is conv5_block4_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 393 , the name of the layer is conv5_block4_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 394 , the name of the layer is conv5_block4_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 395 , the name of the layer is conv5_block4_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 396 , the name of the layer is conv5_block4_concat, the output is (?, 16, 16, 768)\n",
      "The index is 397 , the name of the layer is conv5_block5_0_bn, the output is (?, 16, 16, 768)\n",
      "The index is 398 , the name of the layer is conv5_block5_0_relu, the output is (?, 16, 16, 768)\n",
      "The index is 399 , the name of the layer is conv5_block5_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 400 , the name of the layer is conv5_block5_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 401 , the name of the layer is conv5_block5_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 402 , the name of the layer is conv5_block5_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 403 , the name of the layer is conv5_block5_concat, the output is (?, 16, 16, 800)\n",
      "The index is 404 , the name of the layer is conv5_block6_0_bn, the output is (?, 16, 16, 800)\n",
      "The index is 405 , the name of the layer is conv5_block6_0_relu, the output is (?, 16, 16, 800)\n",
      "The index is 406 , the name of the layer is conv5_block6_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 407 , the name of the layer is conv5_block6_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 408 , the name of the layer is conv5_block6_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 409 , the name of the layer is conv5_block6_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 410 , the name of the layer is conv5_block6_concat, the output is (?, 16, 16, 832)\n",
      "The index is 411 , the name of the layer is conv5_block7_0_bn, the output is (?, 16, 16, 832)\n",
      "The index is 412 , the name of the layer is conv5_block7_0_relu, the output is (?, 16, 16, 832)\n",
      "The index is 413 , the name of the layer is conv5_block7_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 414 , the name of the layer is conv5_block7_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 415 , the name of the layer is conv5_block7_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 416 , the name of the layer is conv5_block7_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 417 , the name of the layer is conv5_block7_concat, the output is (?, 16, 16, 864)\n",
      "The index is 418 , the name of the layer is conv5_block8_0_bn, the output is (?, 16, 16, 864)\n",
      "The index is 419 , the name of the layer is conv5_block8_0_relu, the output is (?, 16, 16, 864)\n",
      "The index is 420 , the name of the layer is conv5_block8_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 421 , the name of the layer is conv5_block8_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 422 , the name of the layer is conv5_block8_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 423 , the name of the layer is conv5_block8_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 424 , the name of the layer is conv5_block8_concat, the output is (?, 16, 16, 896)\n",
      "The index is 425 , the name of the layer is conv5_block9_0_bn, the output is (?, 16, 16, 896)\n",
      "The index is 426 , the name of the layer is conv5_block9_0_relu, the output is (?, 16, 16, 896)\n",
      "The index is 427 , the name of the layer is conv5_block9_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 428 , the name of the layer is conv5_block9_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 429 , the name of the layer is conv5_block9_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 430 , the name of the layer is conv5_block9_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 431 , the name of the layer is conv5_block9_concat, the output is (?, 16, 16, 928)\n",
      "The index is 432 , the name of the layer is conv5_block10_0_bn, the output is (?, 16, 16, 928)\n",
      "The index is 433 , the name of the layer is conv5_block10_0_relu, the output is (?, 16, 16, 928)\n",
      "The index is 434 , the name of the layer is conv5_block10_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 435 , the name of the layer is conv5_block10_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 436 , the name of the layer is conv5_block10_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 437 , the name of the layer is conv5_block10_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 438 , the name of the layer is conv5_block10_concat, the output is (?, 16, 16, 960)\n",
      "The index is 439 , the name of the layer is conv5_block11_0_bn, the output is (?, 16, 16, 960)\n",
      "The index is 440 , the name of the layer is conv5_block11_0_relu, the output is (?, 16, 16, 960)\n",
      "The index is 441 , the name of the layer is conv5_block11_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 442 , the name of the layer is conv5_block11_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 443 , the name of the layer is conv5_block11_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 444 , the name of the layer is conv5_block11_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 445 , the name of the layer is conv5_block11_concat, the output is (?, 16, 16, 992)\n",
      "The index is 446 , the name of the layer is conv5_block12_0_bn, the output is (?, 16, 16, 992)\n",
      "The index is 447 , the name of the layer is conv5_block12_0_relu, the output is (?, 16, 16, 992)\n",
      "The index is 448 , the name of the layer is conv5_block12_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 449 , the name of the layer is conv5_block12_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 450 , the name of the layer is conv5_block12_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 451 , the name of the layer is conv5_block12_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 452 , the name of the layer is conv5_block12_concat, the output is (?, 16, 16, 1024)\n",
      "The index is 453 , the name of the layer is conv5_block13_0_bn, the output is (?, 16, 16, 1024)\n",
      "The index is 454 , the name of the layer is conv5_block13_0_relu, the output is (?, 16, 16, 1024)\n",
      "The index is 455 , the name of the layer is conv5_block13_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 456 , the name of the layer is conv5_block13_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 457 , the name of the layer is conv5_block13_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 458 , the name of the layer is conv5_block13_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 459 , the name of the layer is conv5_block13_concat, the output is (?, 16, 16, 1056)\n",
      "The index is 460 , the name of the layer is conv5_block14_0_bn, the output is (?, 16, 16, 1056)\n",
      "The index is 461 , the name of the layer is conv5_block14_0_relu, the output is (?, 16, 16, 1056)\n",
      "The index is 462 , the name of the layer is conv5_block14_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 463 , the name of the layer is conv5_block14_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 464 , the name of the layer is conv5_block14_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 465 , the name of the layer is conv5_block14_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 466 , the name of the layer is conv5_block14_concat, the output is (?, 16, 16, 1088)\n",
      "The index is 467 , the name of the layer is conv5_block15_0_bn, the output is (?, 16, 16, 1088)\n",
      "The index is 468 , the name of the layer is conv5_block15_0_relu, the output is (?, 16, 16, 1088)\n",
      "The index is 469 , the name of the layer is conv5_block15_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 470 , the name of the layer is conv5_block15_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 471 , the name of the layer is conv5_block15_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 472 , the name of the layer is conv5_block15_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 473 , the name of the layer is conv5_block15_concat, the output is (?, 16, 16, 1120)\n",
      "The index is 474 , the name of the layer is conv5_block16_0_bn, the output is (?, 16, 16, 1120)\n",
      "The index is 475 , the name of the layer is conv5_block16_0_relu, the output is (?, 16, 16, 1120)\n",
      "The index is 476 , the name of the layer is conv5_block16_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 477 , the name of the layer is conv5_block16_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 478 , the name of the layer is conv5_block16_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 479 , the name of the layer is conv5_block16_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 480 , the name of the layer is conv5_block16_concat, the output is (?, 16, 16, 1152)\n",
      "The index is 481 , the name of the layer is conv5_block17_0_bn, the output is (?, 16, 16, 1152)\n",
      "The index is 482 , the name of the layer is conv5_block17_0_relu, the output is (?, 16, 16, 1152)\n",
      "The index is 483 , the name of the layer is conv5_block17_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 484 , the name of the layer is conv5_block17_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 485 , the name of the layer is conv5_block17_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 486 , the name of the layer is conv5_block17_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 487 , the name of the layer is conv5_block17_concat, the output is (?, 16, 16, 1184)\n",
      "The index is 488 , the name of the layer is conv5_block18_0_bn, the output is (?, 16, 16, 1184)\n",
      "The index is 489 , the name of the layer is conv5_block18_0_relu, the output is (?, 16, 16, 1184)\n",
      "The index is 490 , the name of the layer is conv5_block18_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 491 , the name of the layer is conv5_block18_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 492 , the name of the layer is conv5_block18_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 493 , the name of the layer is conv5_block18_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 494 , the name of the layer is conv5_block18_concat, the output is (?, 16, 16, 1216)\n",
      "The index is 495 , the name of the layer is conv5_block19_0_bn, the output is (?, 16, 16, 1216)\n",
      "The index is 496 , the name of the layer is conv5_block19_0_relu, the output is (?, 16, 16, 1216)\n",
      "The index is 497 , the name of the layer is conv5_block19_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 498 , the name of the layer is conv5_block19_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 499 , the name of the layer is conv5_block19_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 500 , the name of the layer is conv5_block19_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 501 , the name of the layer is conv5_block19_concat, the output is (?, 16, 16, 1248)\n",
      "The index is 502 , the name of the layer is conv5_block20_0_bn, the output is (?, 16, 16, 1248)\n",
      "The index is 503 , the name of the layer is conv5_block20_0_relu, the output is (?, 16, 16, 1248)\n",
      "The index is 504 , the name of the layer is conv5_block20_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 505 , the name of the layer is conv5_block20_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 506 , the name of the layer is conv5_block20_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 507 , the name of the layer is conv5_block20_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 508 , the name of the layer is conv5_block20_concat, the output is (?, 16, 16, 1280)\n",
      "The index is 509 , the name of the layer is conv5_block21_0_bn, the output is (?, 16, 16, 1280)\n",
      "The index is 510 , the name of the layer is conv5_block21_0_relu, the output is (?, 16, 16, 1280)\n",
      "The index is 511 , the name of the layer is conv5_block21_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 512 , the name of the layer is conv5_block21_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 513 , the name of the layer is conv5_block21_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 514 , the name of the layer is conv5_block21_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 515 , the name of the layer is conv5_block21_concat, the output is (?, 16, 16, 1312)\n",
      "The index is 516 , the name of the layer is conv5_block22_0_bn, the output is (?, 16, 16, 1312)\n",
      "The index is 517 , the name of the layer is conv5_block22_0_relu, the output is (?, 16, 16, 1312)\n",
      "The index is 518 , the name of the layer is conv5_block22_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 519 , the name of the layer is conv5_block22_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 520 , the name of the layer is conv5_block22_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 521 , the name of the layer is conv5_block22_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 522 , the name of the layer is conv5_block22_concat, the output is (?, 16, 16, 1344)\n",
      "The index is 523 , the name of the layer is conv5_block23_0_bn, the output is (?, 16, 16, 1344)\n",
      "The index is 524 , the name of the layer is conv5_block23_0_relu, the output is (?, 16, 16, 1344)\n",
      "The index is 525 , the name of the layer is conv5_block23_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 526 , the name of the layer is conv5_block23_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 527 , the name of the layer is conv5_block23_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 528 , the name of the layer is conv5_block23_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 529 , the name of the layer is conv5_block23_concat, the output is (?, 16, 16, 1376)\n",
      "The index is 530 , the name of the layer is conv5_block24_0_bn, the output is (?, 16, 16, 1376)\n",
      "The index is 531 , the name of the layer is conv5_block24_0_relu, the output is (?, 16, 16, 1376)\n",
      "The index is 532 , the name of the layer is conv5_block24_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 533 , the name of the layer is conv5_block24_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 534 , the name of the layer is conv5_block24_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 535 , the name of the layer is conv5_block24_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 536 , the name of the layer is conv5_block24_concat, the output is (?, 16, 16, 1408)\n",
      "The index is 537 , the name of the layer is conv5_block25_0_bn, the output is (?, 16, 16, 1408)\n",
      "The index is 538 , the name of the layer is conv5_block25_0_relu, the output is (?, 16, 16, 1408)\n",
      "The index is 539 , the name of the layer is conv5_block25_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 540 , the name of the layer is conv5_block25_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 541 , the name of the layer is conv5_block25_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 542 , the name of the layer is conv5_block25_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 543 , the name of the layer is conv5_block25_concat, the output is (?, 16, 16, 1440)\n",
      "The index is 544 , the name of the layer is conv5_block26_0_bn, the output is (?, 16, 16, 1440)\n",
      "The index is 545 , the name of the layer is conv5_block26_0_relu, the output is (?, 16, 16, 1440)\n",
      "The index is 546 , the name of the layer is conv5_block26_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 547 , the name of the layer is conv5_block26_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 548 , the name of the layer is conv5_block26_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 549 , the name of the layer is conv5_block26_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 550 , the name of the layer is conv5_block26_concat, the output is (?, 16, 16, 1472)\n",
      "The index is 551 , the name of the layer is conv5_block27_0_bn, the output is (?, 16, 16, 1472)\n",
      "The index is 552 , the name of the layer is conv5_block27_0_relu, the output is (?, 16, 16, 1472)\n",
      "The index is 553 , the name of the layer is conv5_block27_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 554 , the name of the layer is conv5_block27_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 555 , the name of the layer is conv5_block27_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 556 , the name of the layer is conv5_block27_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 557 , the name of the layer is conv5_block27_concat, the output is (?, 16, 16, 1504)\n",
      "The index is 558 , the name of the layer is conv5_block28_0_bn, the output is (?, 16, 16, 1504)\n",
      "The index is 559 , the name of the layer is conv5_block28_0_relu, the output is (?, 16, 16, 1504)\n",
      "The index is 560 , the name of the layer is conv5_block28_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 561 , the name of the layer is conv5_block28_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 562 , the name of the layer is conv5_block28_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 563 , the name of the layer is conv5_block28_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 564 , the name of the layer is conv5_block28_concat, the output is (?, 16, 16, 1536)\n",
      "The index is 565 , the name of the layer is conv5_block29_0_bn, the output is (?, 16, 16, 1536)\n",
      "The index is 566 , the name of the layer is conv5_block29_0_relu, the output is (?, 16, 16, 1536)\n",
      "The index is 567 , the name of the layer is conv5_block29_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 568 , the name of the layer is conv5_block29_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 569 , the name of the layer is conv5_block29_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 570 , the name of the layer is conv5_block29_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 571 , the name of the layer is conv5_block29_concat, the output is (?, 16, 16, 1568)\n",
      "The index is 572 , the name of the layer is conv5_block30_0_bn, the output is (?, 16, 16, 1568)\n",
      "The index is 573 , the name of the layer is conv5_block30_0_relu, the output is (?, 16, 16, 1568)\n",
      "The index is 574 , the name of the layer is conv5_block30_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 575 , the name of the layer is conv5_block30_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 576 , the name of the layer is conv5_block30_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 577 , the name of the layer is conv5_block30_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 578 , the name of the layer is conv5_block30_concat, the output is (?, 16, 16, 1600)\n",
      "The index is 579 , the name of the layer is conv5_block31_0_bn, the output is (?, 16, 16, 1600)\n",
      "The index is 580 , the name of the layer is conv5_block31_0_relu, the output is (?, 16, 16, 1600)\n",
      "The index is 581 , the name of the layer is conv5_block31_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 582 , the name of the layer is conv5_block31_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 583 , the name of the layer is conv5_block31_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 584 , the name of the layer is conv5_block31_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 585 , the name of the layer is conv5_block31_concat, the output is (?, 16, 16, 1632)\n",
      "The index is 586 , the name of the layer is conv5_block32_0_bn, the output is (?, 16, 16, 1632)\n",
      "The index is 587 , the name of the layer is conv5_block32_0_relu, the output is (?, 16, 16, 1632)\n",
      "The index is 588 , the name of the layer is conv5_block32_1_conv, the output is (?, 16, 16, 128)\n",
      "The index is 589 , the name of the layer is conv5_block32_1_bn, the output is (?, 16, 16, 128)\n",
      "The index is 590 , the name of the layer is conv5_block32_1_relu, the output is (?, 16, 16, 128)\n",
      "The index is 591 , the name of the layer is conv5_block32_2_conv, the output is (?, 16, 16, 32)\n",
      "The index is 592 , the name of the layer is conv5_block32_concat, the output is (?, 16, 16, 1664)\n",
      "The index is 593 , the name of the layer is bn, the output is (?, 16, 16, 1664)\n",
      "The index is 594 , the name of the layer is relu, the output is (?, 16, 16, 1664)\n"
     ]
    }
   ],
   "source": [
    "for idx,layer in enumerate(m1.layers):\n",
    "    print(f'The index is {idx} , the name of the layer is {layer.name}, the output is {layer.output.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(518), Dimension(518), Dimension(3)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.layers[1].output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index is 0 , the name of the layer is input_8, the output is (?, 512, 512, 3)\n",
      "The index is 1 , the name of the layer is block1_conv1, the output is (?, 255, 255, 32)\n",
      "The index is 2 , the name of the layer is block1_conv1_bn, the output is (?, 255, 255, 32)\n",
      "The index is 3 , the name of the layer is block1_conv1_act, the output is (?, 255, 255, 32)\n",
      "The index is 4 , the name of the layer is block1_conv2, the output is (?, 253, 253, 64)\n",
      "The index is 5 , the name of the layer is block1_conv2_bn, the output is (?, 253, 253, 64)\n",
      "The index is 6 , the name of the layer is block1_conv2_act, the output is (?, 253, 253, 64)\n",
      "The index is 7 , the name of the layer is block2_sepconv1, the output is (?, 253, 253, 128)\n",
      "The index is 8 , the name of the layer is block2_sepconv1_bn, the output is (?, 253, 253, 128)\n",
      "The index is 9 , the name of the layer is block2_sepconv2_act, the output is (?, 253, 253, 128)\n",
      "The index is 10 , the name of the layer is block2_sepconv2, the output is (?, 253, 253, 128)\n",
      "The index is 11 , the name of the layer is block2_sepconv2_bn, the output is (?, 253, 253, 128)\n",
      "The index is 12 , the name of the layer is conv2d_163, the output is (?, 127, 127, 128)\n",
      "The index is 13 , the name of the layer is block2_pool, the output is (?, 127, 127, 128)\n",
      "The index is 14 , the name of the layer is batch_normalization_294, the output is (?, 127, 127, 128)\n",
      "The index is 15 , the name of the layer is add_126, the output is (?, 127, 127, 128)\n",
      "The index is 16 , the name of the layer is block3_sepconv1_act, the output is (?, 127, 127, 128)\n",
      "The index is 17 , the name of the layer is block3_sepconv1, the output is (?, 127, 127, 256)\n",
      "The index is 18 , the name of the layer is block3_sepconv1_bn, the output is (?, 127, 127, 256)\n",
      "The index is 19 , the name of the layer is block3_sepconv2_act, the output is (?, 127, 127, 256)\n",
      "The index is 20 , the name of the layer is block3_sepconv2, the output is (?, 127, 127, 256)\n",
      "The index is 21 , the name of the layer is block3_sepconv2_bn, the output is (?, 127, 127, 256)\n",
      "The index is 22 , the name of the layer is conv2d_164, the output is (?, 64, 64, 256)\n",
      "The index is 23 , the name of the layer is block3_pool, the output is (?, 64, 64, 256)\n",
      "The index is 24 , the name of the layer is batch_normalization_295, the output is (?, 64, 64, 256)\n",
      "The index is 25 , the name of the layer is add_127, the output is (?, 64, 64, 256)\n",
      "The index is 26 , the name of the layer is block4_sepconv1_act, the output is (?, 64, 64, 256)\n",
      "The index is 27 , the name of the layer is block4_sepconv1, the output is (?, 64, 64, 728)\n",
      "The index is 28 , the name of the layer is block4_sepconv1_bn, the output is (?, 64, 64, 728)\n",
      "The index is 29 , the name of the layer is block4_sepconv2_act, the output is (?, 64, 64, 728)\n",
      "The index is 30 , the name of the layer is block4_sepconv2, the output is (?, 64, 64, 728)\n",
      "The index is 31 , the name of the layer is block4_sepconv2_bn, the output is (?, 64, 64, 728)\n",
      "The index is 32 , the name of the layer is conv2d_165, the output is (?, 32, 32, 728)\n",
      "The index is 33 , the name of the layer is block4_pool, the output is (?, 32, 32, 728)\n",
      "The index is 34 , the name of the layer is batch_normalization_296, the output is (?, 32, 32, 728)\n",
      "The index is 35 , the name of the layer is add_128, the output is (?, 32, 32, 728)\n",
      "The index is 36 , the name of the layer is block5_sepconv1_act, the output is (?, 32, 32, 728)\n",
      "The index is 37 , the name of the layer is block5_sepconv1, the output is (?, 32, 32, 728)\n",
      "The index is 38 , the name of the layer is block5_sepconv1_bn, the output is (?, 32, 32, 728)\n",
      "The index is 39 , the name of the layer is block5_sepconv2_act, the output is (?, 32, 32, 728)\n",
      "The index is 40 , the name of the layer is block5_sepconv2, the output is (?, 32, 32, 728)\n",
      "The index is 41 , the name of the layer is block5_sepconv2_bn, the output is (?, 32, 32, 728)\n",
      "The index is 42 , the name of the layer is block5_sepconv3_act, the output is (?, 32, 32, 728)\n",
      "The index is 43 , the name of the layer is block5_sepconv3, the output is (?, 32, 32, 728)\n",
      "The index is 44 , the name of the layer is block5_sepconv3_bn, the output is (?, 32, 32, 728)\n",
      "The index is 45 , the name of the layer is add_129, the output is (?, 32, 32, 728)\n",
      "The index is 46 , the name of the layer is block6_sepconv1_act, the output is (?, 32, 32, 728)\n",
      "The index is 47 , the name of the layer is block6_sepconv1, the output is (?, 32, 32, 728)\n",
      "The index is 48 , the name of the layer is block6_sepconv1_bn, the output is (?, 32, 32, 728)\n",
      "The index is 49 , the name of the layer is block6_sepconv2_act, the output is (?, 32, 32, 728)\n",
      "The index is 50 , the name of the layer is block6_sepconv2, the output is (?, 32, 32, 728)\n",
      "The index is 51 , the name of the layer is block6_sepconv2_bn, the output is (?, 32, 32, 728)\n",
      "The index is 52 , the name of the layer is block6_sepconv3_act, the output is (?, 32, 32, 728)\n",
      "The index is 53 , the name of the layer is block6_sepconv3, the output is (?, 32, 32, 728)\n",
      "The index is 54 , the name of the layer is block6_sepconv3_bn, the output is (?, 32, 32, 728)\n",
      "The index is 55 , the name of the layer is add_130, the output is (?, 32, 32, 728)\n",
      "The index is 56 , the name of the layer is block7_sepconv1_act, the output is (?, 32, 32, 728)\n",
      "The index is 57 , the name of the layer is block7_sepconv1, the output is (?, 32, 32, 728)\n",
      "The index is 58 , the name of the layer is block7_sepconv1_bn, the output is (?, 32, 32, 728)\n",
      "The index is 59 , the name of the layer is block7_sepconv2_act, the output is (?, 32, 32, 728)\n",
      "The index is 60 , the name of the layer is block7_sepconv2, the output is (?, 32, 32, 728)\n",
      "The index is 61 , the name of the layer is block7_sepconv2_bn, the output is (?, 32, 32, 728)\n",
      "The index is 62 , the name of the layer is block7_sepconv3_act, the output is (?, 32, 32, 728)\n",
      "The index is 63 , the name of the layer is block7_sepconv3, the output is (?, 32, 32, 728)\n",
      "The index is 64 , the name of the layer is block7_sepconv3_bn, the output is (?, 32, 32, 728)\n",
      "The index is 65 , the name of the layer is add_131, the output is (?, 32, 32, 728)\n",
      "The index is 66 , the name of the layer is block8_sepconv1_act, the output is (?, 32, 32, 728)\n",
      "The index is 67 , the name of the layer is block8_sepconv1, the output is (?, 32, 32, 728)\n",
      "The index is 68 , the name of the layer is block8_sepconv1_bn, the output is (?, 32, 32, 728)\n",
      "The index is 69 , the name of the layer is block8_sepconv2_act, the output is (?, 32, 32, 728)\n",
      "The index is 70 , the name of the layer is block8_sepconv2, the output is (?, 32, 32, 728)\n",
      "The index is 71 , the name of the layer is block8_sepconv2_bn, the output is (?, 32, 32, 728)\n",
      "The index is 72 , the name of the layer is block8_sepconv3_act, the output is (?, 32, 32, 728)\n",
      "The index is 73 , the name of the layer is block8_sepconv3, the output is (?, 32, 32, 728)\n",
      "The index is 74 , the name of the layer is block8_sepconv3_bn, the output is (?, 32, 32, 728)\n",
      "The index is 75 , the name of the layer is add_132, the output is (?, 32, 32, 728)\n",
      "The index is 76 , the name of the layer is block9_sepconv1_act, the output is (?, 32, 32, 728)\n",
      "The index is 77 , the name of the layer is block9_sepconv1, the output is (?, 32, 32, 728)\n",
      "The index is 78 , the name of the layer is block9_sepconv1_bn, the output is (?, 32, 32, 728)\n",
      "The index is 79 , the name of the layer is block9_sepconv2_act, the output is (?, 32, 32, 728)\n",
      "The index is 80 , the name of the layer is block9_sepconv2, the output is (?, 32, 32, 728)\n",
      "The index is 81 , the name of the layer is block9_sepconv2_bn, the output is (?, 32, 32, 728)\n",
      "The index is 82 , the name of the layer is block9_sepconv3_act, the output is (?, 32, 32, 728)\n",
      "The index is 83 , the name of the layer is block9_sepconv3, the output is (?, 32, 32, 728)\n",
      "The index is 84 , the name of the layer is block9_sepconv3_bn, the output is (?, 32, 32, 728)\n",
      "The index is 85 , the name of the layer is add_133, the output is (?, 32, 32, 728)\n",
      "The index is 86 , the name of the layer is block10_sepconv1_act, the output is (?, 32, 32, 728)\n",
      "The index is 87 , the name of the layer is block10_sepconv1, the output is (?, 32, 32, 728)\n",
      "The index is 88 , the name of the layer is block10_sepconv1_bn, the output is (?, 32, 32, 728)\n",
      "The index is 89 , the name of the layer is block10_sepconv2_act, the output is (?, 32, 32, 728)\n",
      "The index is 90 , the name of the layer is block10_sepconv2, the output is (?, 32, 32, 728)\n",
      "The index is 91 , the name of the layer is block10_sepconv2_bn, the output is (?, 32, 32, 728)\n",
      "The index is 92 , the name of the layer is block10_sepconv3_act, the output is (?, 32, 32, 728)\n",
      "The index is 93 , the name of the layer is block10_sepconv3, the output is (?, 32, 32, 728)\n",
      "The index is 94 , the name of the layer is block10_sepconv3_bn, the output is (?, 32, 32, 728)\n",
      "The index is 95 , the name of the layer is add_134, the output is (?, 32, 32, 728)\n",
      "The index is 96 , the name of the layer is block11_sepconv1_act, the output is (?, 32, 32, 728)\n",
      "The index is 97 , the name of the layer is block11_sepconv1, the output is (?, 32, 32, 728)\n",
      "The index is 98 , the name of the layer is block11_sepconv1_bn, the output is (?, 32, 32, 728)\n",
      "The index is 99 , the name of the layer is block11_sepconv2_act, the output is (?, 32, 32, 728)\n",
      "The index is 100 , the name of the layer is block11_sepconv2, the output is (?, 32, 32, 728)\n",
      "The index is 101 , the name of the layer is block11_sepconv2_bn, the output is (?, 32, 32, 728)\n",
      "The index is 102 , the name of the layer is block11_sepconv3_act, the output is (?, 32, 32, 728)\n",
      "The index is 103 , the name of the layer is block11_sepconv3, the output is (?, 32, 32, 728)\n",
      "The index is 104 , the name of the layer is block11_sepconv3_bn, the output is (?, 32, 32, 728)\n",
      "The index is 105 , the name of the layer is add_135, the output is (?, 32, 32, 728)\n",
      "The index is 106 , the name of the layer is block12_sepconv1_act, the output is (?, 32, 32, 728)\n",
      "The index is 107 , the name of the layer is block12_sepconv1, the output is (?, 32, 32, 728)\n",
      "The index is 108 , the name of the layer is block12_sepconv1_bn, the output is (?, 32, 32, 728)\n",
      "The index is 109 , the name of the layer is block12_sepconv2_act, the output is (?, 32, 32, 728)\n",
      "The index is 110 , the name of the layer is block12_sepconv2, the output is (?, 32, 32, 728)\n",
      "The index is 111 , the name of the layer is block12_sepconv2_bn, the output is (?, 32, 32, 728)\n",
      "The index is 112 , the name of the layer is block12_sepconv3_act, the output is (?, 32, 32, 728)\n",
      "The index is 113 , the name of the layer is block12_sepconv3, the output is (?, 32, 32, 728)\n",
      "The index is 114 , the name of the layer is block12_sepconv3_bn, the output is (?, 32, 32, 728)\n",
      "The index is 115 , the name of the layer is add_136, the output is (?, 32, 32, 728)\n",
      "The index is 116 , the name of the layer is block13_sepconv1_act, the output is (?, 32, 32, 728)\n",
      "The index is 117 , the name of the layer is block13_sepconv1, the output is (?, 32, 32, 728)\n",
      "The index is 118 , the name of the layer is block13_sepconv1_bn, the output is (?, 32, 32, 728)\n",
      "The index is 119 , the name of the layer is block13_sepconv2_act, the output is (?, 32, 32, 728)\n",
      "The index is 120 , the name of the layer is block13_sepconv2, the output is (?, 32, 32, 1024)\n",
      "The index is 121 , the name of the layer is block13_sepconv2_bn, the output is (?, 32, 32, 1024)\n",
      "The index is 122 , the name of the layer is conv2d_166, the output is (?, 16, 16, 1024)\n",
      "The index is 123 , the name of the layer is block13_pool, the output is (?, 16, 16, 1024)\n",
      "The index is 124 , the name of the layer is batch_normalization_297, the output is (?, 16, 16, 1024)\n",
      "The index is 125 , the name of the layer is add_137, the output is (?, 16, 16, 1024)\n",
      "The index is 126 , the name of the layer is block14_sepconv1, the output is (?, 16, 16, 1536)\n",
      "The index is 127 , the name of the layer is block14_sepconv1_bn, the output is (?, 16, 16, 1536)\n",
      "The index is 128 , the name of the layer is block14_sepconv1_act, the output is (?, 16, 16, 1536)\n",
      "The index is 129 , the name of the layer is block14_sepconv2, the output is (?, 16, 16, 2048)\n",
      "The index is 130 , the name of the layer is block14_sepconv2_bn, the output is (?, 16, 16, 2048)\n",
      "The index is 131 , the name of the layer is block14_sepconv2_act, the output is (?, 16, 16, 2048)\n"
     ]
    }
   ],
   "source": [
    "for idx,layer in enumerate(uxception.layers):\n",
    "    print(f'The index is {idx} , the name of the layer is {layer.name}, the output is {layer.output.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "579,361,309,133,45,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unet_dense(input_shape=(None, None, 3),dropout_rate=0.5,start_neurons=16):\n",
    "    \n",
    "    backbone = Densenet(input_shape=input_shape,weights='imagenet',include_top=False)\n",
    "    input = backbone.input\n",
    "    \n",
    "    conv4 = backbone.layers[361].output # 32,32,1024 #16,16,1600\n",
    "    conv4 = LeakyReLU(alpha=0.1)(conv4) # 32,32,1024 #16,16,1600\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4) # 16,16,1024  #8,8,1600\n",
    "    pool4 = Dropout(dropout_rate)(pool4) # 16,16,1024 #8,8,1600\n",
    "    \n",
    "    #Middle \n",
    "    convm = convolutional_block(pool4,start_neurons=16,multiplying_factor=32) # m64, 8,8,1024\n",
    "    \n",
    "#     deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm) # 32,32,256\n",
    "#     uconv4 = concatenate([deconv4, conv4]) # 32,32,1280\n",
    "#     uconv4 = Dropout(dropout_rate)(uconv4) # 32,32,1280\n",
    "    \n",
    "    \n",
    "    #Decoder\n",
    "    uconv4 = upconv_block(backbone,convm,layer_number=361,start_neurons=16,multiplying_factor=16,dropout_rate=0.5,padding_flag=False)\n",
    "    uconv4 = convolutional_block(uconv4,start_neurons=16,multiplying_factor=16)\n",
    "    \n",
    "    uconv3 = upconv_block(backbone,uconv4,layer_number=133,start_neurons=16,multiplying_factor=8,padding_flag=False,dropout_rate=0.5)\n",
    "    uconv3 = convolutional_block(uconv3,start_neurons=16,multiplying_factor=8)\n",
    "    \n",
    "    uconv2 = upconv_block(backbone,uconv3,layer_number=45,start_neurons=16,multiplying_factor=4,padding_kernel=1,padding_flag=False)\n",
    "    uconv2 = convolutional_block(uconv2,start_neurons=16,multiplying_factor=4)\n",
    "    \n",
    "    uconv1 = upconv_block(backbone,uconv2,layer_number=3,start_neurons=16,multiplying_factor=2,padding_kernel=3,padding_flag=False)\n",
    "    uconv1 = convolutional_block(uconv1,start_neurons=16,multiplying_factor=2)\n",
    "    \n",
    "    uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)   # 512,512,16\n",
    "    uconv0 = Dropout(dropout_rate)(uconv0) #512,512,16\n",
    "    uconv0 = convolutional_block(uconv0,start_neurons=16,multiplying_factor=1,strides=(1,1))\n",
    "    \n",
    "    uconv0 = Dropout(dropout_rate/2)(uconv0) # 512,512,16\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv0)    # 512,512,1\n",
    "    \n",
    "    model = Model(input, output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 24, 24, 512)\n",
      "(?, 24, 24, 512)\n",
      "(?, 24, 24, 512)\n",
      "(?, 24, 24, 512)\n",
      "The input block shape is (?, 24, 24, 512)\n",
      "The layer output is (?, 48, 48, 128)\n",
      "The upconv output is shape (?, 48, 48, 256)\n",
      "The padding flag is set to False and padding is 1\n",
      "(?, 48, 48, 256)\n",
      "(?, 48, 48, 256)\n",
      "(?, 48, 48, 256)\n",
      "(?, 48, 48, 256)\n",
      "The input block shape is (?, 48, 48, 256)\n",
      "The layer output is (?, 96, 96, 128)\n",
      "The upconv output is shape (?, 96, 96, 128)\n",
      "The padding flag is set to False and padding is 1\n",
      "(?, 96, 96, 128)\n",
      "(?, 96, 96, 128)\n",
      "(?, 96, 96, 128)\n",
      "(?, 96, 96, 128)\n",
      "The input block shape is (?, 96, 96, 128)\n",
      "The layer output is (?, 192, 192, 128)\n",
      "The upconv output is shape (?, 192, 192, 64)\n",
      "The padding flag is set to False and padding is 1\n",
      "(?, 192, 192, 64)\n",
      "(?, 192, 192, 64)\n",
      "(?, 192, 192, 64)\n",
      "(?, 192, 192, 64)\n",
      "The input block shape is (?, 192, 192, 64)\n",
      "The layer output is (?, 384, 384, 64)\n",
      "The upconv output is shape (?, 384, 384, 32)\n",
      "The padding flag is set to False and padding is 3\n",
      "(?, 384, 384, 32)\n",
      "(?, 384, 384, 32)\n",
      "(?, 384, 384, 32)\n",
      "(?, 384, 384, 32)\n",
      "(?, 768, 768, 16)\n",
      "(?, 768, 768, 16)\n",
      "(?, 768, 768, 16)\n",
      "(?, 768, 768, 16)\n"
     ]
    }
   ],
   "source": [
    "den = Unet_dense(input_shape=(768,768,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 768, 768, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 774, 774, 3)  0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 384, 384, 64) 9408        zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 384, 384, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 384, 384, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 386, 386, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 192, 192, 64) 0           zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 192, 192, 64) 256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 192, 192, 64) 0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 192, 192, 128 8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 192, 192, 128 512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 192, 192, 128 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 192, 192, 32) 36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 192, 192, 96) 0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 192, 192, 96) 384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 192, 192, 96) 0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 192, 192, 128 12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 192, 192, 128 512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 192, 192, 128 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 192, 192, 32) 36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 192, 192, 128 0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 192, 192, 128 512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 192, 192, 128 0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 192, 192, 128 16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 192, 192, 128 512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 192, 192, 128 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 192, 192, 32) 36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 192, 192, 160 0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 192, 192, 160 640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 192, 192, 160 0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 192, 192, 128 20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 192, 192, 128 512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 192, 192, 128 0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 192, 192, 32) 36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 192, 192, 192 0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 192, 192, 192 768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 192, 192, 192 0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 192, 192, 128 24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 192, 192, 128 512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 192, 192, 128 0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 192, 192, 32) 36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 192, 192, 224 0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 192, 192, 224 896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 192, 192, 224 0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 192, 192, 128 28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 192, 192, 128 512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 192, 192, 128 0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 192, 192, 32) 36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 192, 192, 256 0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 192, 192, 256 1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 192, 192, 256 0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 192, 192, 128 32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 96, 96, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 96, 96, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 96, 96, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 96, 96, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 96, 96, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 96, 96, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 96, 96, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 96, 96, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 96, 96, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 96, 96, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 96, 96, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 96, 96, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 96, 96, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 96, 96, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 96, 96, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 96, 96, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 96, 96, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 96, 96, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 96, 96, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 96, 96, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 96, 96, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 96, 96, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 96, 96, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 96, 96, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 96, 96, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 96, 96, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 96, 96, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 96, 96, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 96, 96, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 96, 96, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 96, 96, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 96, 96, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 96, 96, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 96, 96, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 96, 96, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 96, 96, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 96, 96, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 96, 96, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 96, 96, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 96, 96, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 96, 96, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 96, 96, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 96, 96, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 96, 96, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 96, 96, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 96, 96, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 96, 96, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 96, 96, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 96, 96, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 96, 96, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 96, 96, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 96, 96, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 96, 96, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 96, 96, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 96, 96, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 96, 96, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 96, 96, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 96, 96, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 96, 96, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 96, 96, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 96, 96, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 96, 96, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 96, 96, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 96, 96, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 96, 96, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 96, 96, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 96, 96, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 96, 96, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 96, 96, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 96, 96, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 96, 96, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 96, 96, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 96, 96, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 96, 96, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 96, 96, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 96, 96, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 96, 96, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 96, 96, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 96, 96, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 96, 96, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 96, 96, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 96, 96, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 96, 96, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 96, 96, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 96, 96, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 96, 96, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 96, 96, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 96, 96, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 48, 48, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 48, 48, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 48, 48, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 48, 48, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 48, 48, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 48, 48, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 48, 48, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 48, 48, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 48, 48, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 48, 48, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 48, 48, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 48, 48, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 48, 48, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 48, 48, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 48, 48, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 48, 48, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 48, 48, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 48, 48, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 48, 48, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 48, 48, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 48, 48, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 48, 48, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 48, 48, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 48, 48, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 48, 48, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 48, 48, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 48, 48, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 48, 48, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 48, 48, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 48, 48, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 48, 48, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 48, 48, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 48, 48, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 48, 48, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 48, 48, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 48, 48, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 48, 48, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 48, 48, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 48, 48, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 48, 48, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 48, 48, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 48, 48, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 48, 48, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 48, 48, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 48, 48, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 48, 48, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 48, 48, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 48, 48, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 48, 48, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 48, 48, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 48, 48, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 48, 48, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 48, 48, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 48, 48, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 48, 48, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 48, 48, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 48, 48, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 48, 48, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 48, 48, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 48, 48, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 48, 48, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 48, 48, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 48, 48, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 48, 48, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 48, 48, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 48, 48, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 48, 48, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 48, 48, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 48, 48, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 48, 48, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 48, 48, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 48, 48, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 48, 48, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 48, 48, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 48, 48, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 48, 48, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 48, 48, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 48, 48, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 48, 48, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 48, 48, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 48, 48, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 48, 48, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 48, 48, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 48, 48, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 48, 48, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 48, 48, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 48, 48, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 48, 48, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 48, 48, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 48, 48, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 48, 48, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 48, 48, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 48, 48, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 48, 48, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 48, 48, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 48, 48, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 48, 48, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 48, 48, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 48, 48, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 48, 48, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 48, 48, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 48, 48, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 48, 48, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 48, 48, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 48, 48, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 48, 48, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 48, 48, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 48, 48, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 48, 48, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 48, 48, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 48, 48, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 48, 48, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 48, 48, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 48, 48, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 48, 48, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 48, 48, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 48, 48, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 48, 48, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 48, 48, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 48, 48, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 48, 48, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 48, 48, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 48, 48, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 48, 48, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_bn (BatchNormal (None, 48, 48, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_relu (Activatio (None, 48, 48, 1024) 0           conv4_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 48, 48, 128)  131072      conv4_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_concat (Concatena (None, 48, 48, 1056) 0           conv4_block24_concat[0][0]       \n",
      "                                                                 conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_bn (BatchNormal (None, 48, 48, 1056) 4224        conv4_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_relu (Activatio (None, 48, 48, 1056) 0           conv4_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 48, 48, 128)  135168      conv4_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_concat (Concatena (None, 48, 48, 1088) 0           conv4_block25_concat[0][0]       \n",
      "                                                                 conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_bn (BatchNormal (None, 48, 48, 1088) 4352        conv4_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_relu (Activatio (None, 48, 48, 1088) 0           conv4_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 48, 48, 128)  139264      conv4_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_concat (Concatena (None, 48, 48, 1120) 0           conv4_block26_concat[0][0]       \n",
      "                                                                 conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_bn (BatchNormal (None, 48, 48, 1120) 4480        conv4_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_relu (Activatio (None, 48, 48, 1120) 0           conv4_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 48, 48, 128)  143360      conv4_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block28_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_concat (Concatena (None, 48, 48, 1152) 0           conv4_block27_concat[0][0]       \n",
      "                                                                 conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_bn (BatchNormal (None, 48, 48, 1152) 4608        conv4_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_relu (Activatio (None, 48, 48, 1152) 0           conv4_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 48, 48, 128)  147456      conv4_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_concat (Concatena (None, 48, 48, 1184) 0           conv4_block28_concat[0][0]       \n",
      "                                                                 conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_bn (BatchNormal (None, 48, 48, 1184) 4736        conv4_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_relu (Activatio (None, 48, 48, 1184) 0           conv4_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 48, 48, 128)  151552      conv4_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_concat (Concatena (None, 48, 48, 1216) 0           conv4_block29_concat[0][0]       \n",
      "                                                                 conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_bn (BatchNormal (None, 48, 48, 1216) 4864        conv4_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_relu (Activatio (None, 48, 48, 1216) 0           conv4_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 48, 48, 128)  155648      conv4_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 48, 48, 128)  0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 48, 48, 32)   36864       conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_concat (Concatena (None, 48, 48, 1248) 0           conv4_block30_concat[0][0]       \n",
      "                                                                 conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_bn (BatchNormal (None, 48, 48, 1248) 4992        conv4_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_relu (Activatio (None, 48, 48, 1248) 0           conv4_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 48, 48, 128)  159744      conv4_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 48, 48, 128)  512         conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (None, 48, 48, 128)  0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 24, 24, 128)  0           leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 24, 24, 128)  0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 24, 24, 512)  590336      dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 24, 24, 512)  0           conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_389 (BatchN (None, 24, 24, 512)  2048        activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 24, 24, 512)  2359808     batch_normalization_389[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_390 (BatchN (None, 24, 24, 512)  2048        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 24, 24, 512)  0           batch_normalization_390[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 24, 24, 512)  2359808     activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_391 (BatchN (None, 24, 24, 512)  2048        conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_392 (BatchN (None, 24, 24, 512)  2048        batch_normalization_391[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_388 (BatchN (None, 24, 24, 512)  2048        conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_156 (Add)                   (None, 24, 24, 512)  0           batch_normalization_392[0][0]    \n",
      "                                                                 batch_normalization_388[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 24, 24, 512)  0           add_156[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_394 (BatchN (None, 24, 24, 512)  2048        activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 24, 24, 512)  2359808     batch_normalization_394[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_395 (BatchN (None, 24, 24, 512)  2048        conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 24, 24, 512)  0           batch_normalization_395[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 24, 24, 512)  2359808     activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_396 (BatchN (None, 24, 24, 512)  2048        conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_397 (BatchN (None, 24, 24, 512)  2048        batch_normalization_396[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_393 (BatchN (None, 24, 24, 512)  2048        add_156[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_157 (Add)                   (None, 24, 24, 512)  0           batch_normalization_397[0][0]    \n",
      "                                                                 batch_normalization_393[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (None, 24, 24, 512)  0           add_157[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_31 (Conv2DTran (None, 48, 48, 256)  1179904     leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 48, 48, 384)  0           conv2d_transpose_31[0][0]        \n",
      "                                                                 conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 48, 48, 384)  0           concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 48, 48, 256)  884992      dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 48, 48, 256)  0           conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_399 (BatchN (None, 48, 48, 256)  1024        activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 48, 48, 256)  590080      batch_normalization_399[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_400 (BatchN (None, 48, 48, 256)  1024        conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 48, 48, 256)  0           batch_normalization_400[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 48, 48, 256)  590080      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_401 (BatchN (None, 48, 48, 256)  1024        conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_402 (BatchN (None, 48, 48, 256)  1024        batch_normalization_401[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_398 (BatchN (None, 48, 48, 256)  1024        conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_158 (Add)                   (None, 48, 48, 256)  0           batch_normalization_402[0][0]    \n",
      "                                                                 batch_normalization_398[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 48, 48, 256)  0           add_158[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_404 (BatchN (None, 48, 48, 256)  1024        activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 48, 48, 256)  590080      batch_normalization_404[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_405 (BatchN (None, 48, 48, 256)  1024        conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 48, 48, 256)  0           batch_normalization_405[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 48, 48, 256)  590080      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_406 (BatchN (None, 48, 48, 256)  1024        conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_407 (BatchN (None, 48, 48, 256)  1024        batch_normalization_406[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_403 (BatchN (None, 48, 48, 256)  1024        add_158[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_159 (Add)                   (None, 48, 48, 256)  0           batch_normalization_407[0][0]    \n",
      "                                                                 batch_normalization_403[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)      (None, 48, 48, 256)  0           add_159[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_32 (Conv2DTran (None, 96, 96, 128)  295040      leaky_re_lu_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 96, 96, 256)  0           conv2d_transpose_32[0][0]        \n",
      "                                                                 conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 96, 96, 256)  0           concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 96, 96, 128)  295040      dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 96, 96, 128)  0           conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_409 (BatchN (None, 96, 96, 128)  512         activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 96, 96, 128)  147584      batch_normalization_409[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_410 (BatchN (None, 96, 96, 128)  512         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 96, 96, 128)  0           batch_normalization_410[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 96, 96, 128)  147584      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_411 (BatchN (None, 96, 96, 128)  512         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_412 (BatchN (None, 96, 96, 128)  512         batch_normalization_411[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_408 (BatchN (None, 96, 96, 128)  512         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_160 (Add)                   (None, 96, 96, 128)  0           batch_normalization_412[0][0]    \n",
      "                                                                 batch_normalization_408[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 96, 96, 128)  0           add_160[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_414 (BatchN (None, 96, 96, 128)  512         activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 96, 96, 128)  147584      batch_normalization_414[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_415 (BatchN (None, 96, 96, 128)  512         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 96, 96, 128)  0           batch_normalization_415[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 96, 96, 128)  147584      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_416 (BatchN (None, 96, 96, 128)  512         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_417 (BatchN (None, 96, 96, 128)  512         batch_normalization_416[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_413 (BatchN (None, 96, 96, 128)  512         add_160[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_161 (Add)                   (None, 96, 96, 128)  0           batch_normalization_417[0][0]    \n",
      "                                                                 batch_normalization_413[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)      (None, 96, 96, 128)  0           add_161[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_33 (Conv2DTran (None, 192, 192, 64) 73792       leaky_re_lu_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 192, 192, 192 0           conv2d_transpose_33[0][0]        \n",
      "                                                                 conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 192, 192, 192 0           concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 192, 192, 64) 110656      dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 192, 192, 64) 0           conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_419 (BatchN (None, 192, 192, 64) 256         activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 192, 192, 64) 36928       batch_normalization_419[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_420 (BatchN (None, 192, 192, 64) 256         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 192, 192, 64) 0           batch_normalization_420[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 192, 192, 64) 36928       activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_421 (BatchN (None, 192, 192, 64) 256         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_422 (BatchN (None, 192, 192, 64) 256         batch_normalization_421[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_418 (BatchN (None, 192, 192, 64) 256         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_162 (Add)                   (None, 192, 192, 64) 0           batch_normalization_422[0][0]    \n",
      "                                                                 batch_normalization_418[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 192, 192, 64) 0           add_162[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_424 (BatchN (None, 192, 192, 64) 256         activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 192, 192, 64) 36928       batch_normalization_424[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_425 (BatchN (None, 192, 192, 64) 256         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 192, 192, 64) 0           batch_normalization_425[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 192, 192, 64) 36928       activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_426 (BatchN (None, 192, 192, 64) 256         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_427 (BatchN (None, 192, 192, 64) 256         batch_normalization_426[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_423 (BatchN (None, 192, 192, 64) 256         add_162[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_163 (Add)                   (None, 192, 192, 64) 0           batch_normalization_427[0][0]    \n",
      "                                                                 batch_normalization_423[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)      (None, 192, 192, 64) 0           add_163[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_34 (Conv2DTran (None, 384, 384, 32) 18464       leaky_re_lu_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 384, 384, 96) 0           conv2d_transpose_34[0][0]        \n",
      "                                                                 conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 384, 384, 96) 0           concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 384, 384, 32) 27680       dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 384, 384, 32) 0           conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_429 (BatchN (None, 384, 384, 32) 128         activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 384, 384, 32) 9248        batch_normalization_429[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_430 (BatchN (None, 384, 384, 32) 128         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 384, 384, 32) 0           batch_normalization_430[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 384, 384, 32) 9248        activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_431 (BatchN (None, 384, 384, 32) 128         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_432 (BatchN (None, 384, 384, 32) 128         batch_normalization_431[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_428 (BatchN (None, 384, 384, 32) 128         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_164 (Add)                   (None, 384, 384, 32) 0           batch_normalization_432[0][0]    \n",
      "                                                                 batch_normalization_428[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 384, 384, 32) 0           add_164[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_434 (BatchN (None, 384, 384, 32) 128         activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 384, 384, 32) 9248        batch_normalization_434[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_435 (BatchN (None, 384, 384, 32) 128         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 384, 384, 32) 0           batch_normalization_435[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 384, 384, 32) 9248        activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_436 (BatchN (None, 384, 384, 32) 128         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_437 (BatchN (None, 384, 384, 32) 128         batch_normalization_436[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_433 (BatchN (None, 384, 384, 32) 128         add_164[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_165 (Add)                   (None, 384, 384, 32) 0           batch_normalization_437[0][0]    \n",
      "                                                                 batch_normalization_433[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)      (None, 384, 384, 32) 0           add_165[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_35 (Conv2DTran (None, 768, 768, 16) 4624        leaky_re_lu_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 768, 768, 16) 0           conv2d_transpose_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 768, 768, 16) 2320        dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 768, 768, 16) 0           conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_439 (BatchN (None, 768, 768, 16) 64          activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 768, 768, 16) 2320        batch_normalization_439[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_440 (BatchN (None, 768, 768, 16) 64          conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 768, 768, 16) 0           batch_normalization_440[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 768, 768, 16) 2320        activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_441 (BatchN (None, 768, 768, 16) 64          conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_442 (BatchN (None, 768, 768, 16) 64          batch_normalization_441[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_438 (BatchN (None, 768, 768, 16) 64          conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_166 (Add)                   (None, 768, 768, 16) 0           batch_normalization_442[0][0]    \n",
      "                                                                 batch_normalization_438[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 768, 768, 16) 0           add_166[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_444 (BatchN (None, 768, 768, 16) 64          activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 768, 768, 16) 2320        batch_normalization_444[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_445 (BatchN (None, 768, 768, 16) 64          conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 768, 768, 16) 0           batch_normalization_445[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 768, 768, 16) 2320        activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_446 (BatchN (None, 768, 768, 16) 64          conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_447 (BatchN (None, 768, 768, 16) 64          batch_normalization_446[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_443 (BatchN (None, 768, 768, 16) 64          add_166[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_167 (Add)                   (None, 768, 768, 16) 0           batch_normalization_447[0][0]    \n",
      "                                                                 batch_normalization_443[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)      (None, 768, 768, 16) 0           add_167[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 768, 768, 16) 0           leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 768, 768, 1)  17          dropout_47[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,887,601\n",
      "Trainable params: 21,795,825\n",
      "Non-trainable params: 91,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "den.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
